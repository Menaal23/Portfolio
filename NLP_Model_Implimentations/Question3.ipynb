{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7X1Ellv1RWN",
        "outputId": "9ca4e567-76f0-4d06-96d0-7b3dcdaf3bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ISWCm1Vcjbw"
      },
      "source": [
        "# **QUESTION 3**\n",
        "Seq to seq model implementation\n",
        "Train the following models separately as encoder-decoder frameworks for machine translation:\n",
        "1. RNN-Based Sequence-to-Sequence Model\n",
        "2. Bi-directional RNN Model\n",
        "3. LSTM-Based Sequence-to-Sequence Model\n",
        "4. Transformer-Based Model (using multi-head attention)\n",
        "To ensure a fair comparison between the RNN, BiRNN, LSTM, BiLSTM, and Transformer\n",
        "models, all models must use the same core training configurations. Train each model for at least\n",
        "50 epochs. Vocabulary size and padding must be consistent across all models. You can experiment\n",
        "with different hyperparameters (number of layers, drop out rate, optimizer) for better results and\n",
        "report all hyperparameters as a table.\n",
        "Evaluation and Comparison\n",
        "1. Translate a fixed set of test English sentences to Urdu using all five models.\n",
        "2. Evaluate using BLEU Score\n",
        "3. Record and compare:\n",
        "o Final scores (BLEU)\n",
        "o Inference examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O55BHSy11u-",
        "outputId": "5c638f19-37af-4943-892a-b243648f35fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, SimpleRNN, LSTM, Dense, Bidirectional, GRU, MultiHeadAttention, LayerNormalization, Dropout, Add\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import sentence_bleu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0NQBOYfP3Ln9"
      },
      "outputs": [],
      "source": [
        "# Load the files\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/english-corpus.txt', 'r', encoding='utf-8') as f:\n",
        "    english_lines = f.read().splitlines()\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/urdu-corpus.txt', 'r', encoding='utf-8') as f:\n",
        "    urdu_lines = f.read().splitlines()\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'english': english_lines, 'urdu': urdu_lines}).dropna()\n",
        "\n",
        "# Add <sos> and <eos> tokens to Urdu (target)\n",
        "df['urdu'] = df['urdu'].apply(lambda x: '<sos> ' + x + ' <eos>')\n",
        "\n",
        "# Tokenization\n",
        "eng_tokenizer = Tokenizer(oov_token='<OOV>', filters='')\n",
        "urdu_tokenizer = Tokenizer(oov_token='<OOV>', filters='')\n",
        "\n",
        "eng_tokenizer.fit_on_texts(df['english'])\n",
        "urdu_tokenizer.fit_on_texts(df['urdu'])\n",
        "\n",
        "# Convert to sequences\n",
        "input_seq = eng_tokenizer.texts_to_sequences(df['english'])\n",
        "target_seq = urdu_tokenizer.texts_to_sequences(df['urdu'])\n",
        "\n",
        "# Padding\n",
        "max_input_len = max(len(seq) for seq in input_seq)\n",
        "max_target_len = max(len(seq) for seq in target_seq)\n",
        "\n",
        "encoder_input = pad_sequences(input_seq, maxlen=max_input_len, padding='post')\n",
        "decoder_input = pad_sequences(target_seq, maxlen=max_target_len, padding='post')\n",
        "\n",
        "# Prepare decoder target (right-shifted decoder input)\n",
        "decoder_target = np.zeros_like(decoder_input)\n",
        "decoder_target[:, :-1] = decoder_input[:, 1:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y3P2XMLL3O_6"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE_EN = len(eng_tokenizer.word_index) + 1\n",
        "VOCAB_SIZE_UR = len(urdu_tokenizer.word_index) + 1\n",
        "EMBEDDING_DIM = 256\n",
        "UNITS = 512\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Bd-bQWKW3SOZ"
      },
      "outputs": [],
      "source": [
        "def build_seq2seq_model(cell_type='rnn', bidirectional=False):\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(max_input_len,))\n",
        "    encoder_embedding = Embedding(VOCAB_SIZE_EN, EMBEDDING_DIM)(encoder_inputs)\n",
        "\n",
        "    if cell_type == 'lstm':\n",
        "        if bidirectional:\n",
        "            encoder_outputs, forward_h, forward_c, backward_h, backward_c = Bidirectional(\n",
        "                LSTM(UNITS, return_state=True)\n",
        "            )(encoder_embedding)\n",
        "            state_h = Concatenate()([forward_h, backward_h])\n",
        "            state_c = Concatenate()([forward_c, backward_c])\n",
        "        else:\n",
        "            encoder_outputs, state_h, state_c = LSTM(UNITS, return_state=True)(encoder_embedding)\n",
        "    else:\n",
        "        if bidirectional:\n",
        "            encoder_outputs, forward_h, backward_h = Bidirectional(\n",
        "                SimpleRNN(UNITS, return_state=True)\n",
        "            )(encoder_embedding)\n",
        "            state_h = Concatenate()([forward_h, backward_h])\n",
        "            state_c = None\n",
        "        else:\n",
        "            encoder_outputs, state_h = SimpleRNN(UNITS, return_state=True)(encoder_embedding)\n",
        "            state_c = None\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(max_target_len,))\n",
        "    decoder_embedding = Embedding(VOCAB_SIZE_UR, EMBEDDING_DIM)(decoder_inputs)\n",
        "\n",
        "    if cell_type == 'lstm':\n",
        "        if bidirectional:\n",
        "            decoder_lstm = LSTM(UNITS * 2, return_sequences=True)\n",
        "            decoder_outputs = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "        else:\n",
        "            decoder_lstm = LSTM(UNITS, return_sequences=True)\n",
        "            decoder_outputs = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "    else:\n",
        "        if bidirectional:\n",
        "            decoder_rnn = SimpleRNN(UNITS * 2, return_sequences=True)\n",
        "            decoder_outputs = decoder_rnn(decoder_embedding, initial_state=[state_h])\n",
        "        else:\n",
        "            decoder_rnn = SimpleRNN(UNITS, return_sequences=True)\n",
        "            decoder_outputs = decoder_rnn(decoder_embedding, initial_state=[state_h])\n",
        "\n",
        "    decoder_dense = Dense(VOCAB_SIZE_UR, activation='softmax')\n",
        "    output = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bCVji0Ax3UH2"
      },
      "outputs": [],
      "source": [
        "def build_transformer_model():\n",
        "    inputs = Input(shape=(max_input_len,))\n",
        "    x = Embedding(VOCAB_SIZE_EN, EMBEDDING_DIM)(inputs)\n",
        "    x = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(UNITS, activation='relu')(x)\n",
        "    x = Dense(VOCAB_SIZE_UR, activation='softmax')(x)\n",
        "    model = Model(inputs, x)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WSy-BiJC3V7K"
      },
      "outputs": [],
      "source": [
        "def train_model(model, model_name):\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(\n",
        "        [encoder_input, decoder_input], decoder_target,\n",
        "        batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "    model.save(f\"{model_name}_model.h5\")\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_bleu(model, sample_indices):\n",
        "    bleu_scores = []\n",
        "\n",
        "    for idx in sample_indices:\n",
        "        input_seq = encoder_input[idx:idx+1]\n",
        "        true_output = df['urdu'].iloc[idx].replace('<sos>', '').replace('<eos>', '')\n",
        "        prediction = model.predict([input_seq, decoder_input[idx:idx+1]])\n",
        "        predicted_seq = np.argmax(prediction[0], axis=1)\n",
        "        predicted_words = [urdu_tokenizer.index_word.get(i, '') for i in predicted_seq if i != 0]\n",
        "        pred_text = ' '.join(predicted_words).replace('<sos>', '').replace('<eos>', '')\n",
        "\n",
        "        bleu = sentence_bleu([true_output.split()], pred_text.split())\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "        print(f\"\\n🔹Input: {df['english'].iloc[idx]}\")\n",
        "        print(f\"🔹Target: {true_output}\")\n",
        "        print(f\"🔹Predicted: {pred_text}\")\n",
        "        print(f\"🔹BLEU Score: {bleu:.4f}\")\n",
        "\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    print(f\"\\n✨ Average BLEU Score: {avg_bleu:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InDVcu0h3Xpx",
        "outputId": "1a9a788e-9206-4a96-b34a-d2c009b533cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.7380 - loss: 2.0880 - val_accuracy: 0.7892 - val_loss: 1.2861\n",
            "Epoch 2/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.7926 - loss: 1.2209 - val_accuracy: 0.8032 - val_loss: 1.1545\n",
            "Epoch 3/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8075 - loss: 1.0699 - val_accuracy: 0.8073 - val_loss: 1.1015\n",
            "Epoch 4/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8152 - loss: 0.9774 - val_accuracy: 0.8138 - val_loss: 1.0770\n",
            "Epoch 5/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8214 - loss: 0.9153 - val_accuracy: 0.8154 - val_loss: 1.0729\n",
            "Epoch 6/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8267 - loss: 0.8660 - val_accuracy: 0.8167 - val_loss: 1.0734\n",
            "Epoch 7/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8316 - loss: 0.8255 - val_accuracy: 0.8170 - val_loss: 1.0774\n",
            "Epoch 8/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8373 - loss: 0.7917 - val_accuracy: 0.8192 - val_loss: 1.0725\n",
            "Epoch 9/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8409 - loss: 0.7609 - val_accuracy: 0.8191 - val_loss: 1.0841\n",
            "Epoch 10/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.8456 - loss: 0.7375 - val_accuracy: 0.8198 - val_loss: 1.0909\n",
            "Epoch 11/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8502 - loss: 0.7125 - val_accuracy: 0.8188 - val_loss: 1.0969\n",
            "Epoch 12/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8535 - loss: 0.6927 - val_accuracy: 0.8157 - val_loss: 1.1081\n",
            "Epoch 13/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.8575 - loss: 0.6735 - val_accuracy: 0.8192 - val_loss: 1.1164\n",
            "Epoch 14/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8601 - loss: 0.6591 - val_accuracy: 0.8193 - val_loss: 1.1265\n",
            "Epoch 15/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8637 - loss: 0.6465 - val_accuracy: 0.8150 - val_loss: 1.1326\n",
            "Epoch 16/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8663 - loss: 0.6328 - val_accuracy: 0.8192 - val_loss: 1.1437\n",
            "Epoch 17/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8681 - loss: 0.6249 - val_accuracy: 0.8186 - val_loss: 1.1544\n",
            "Epoch 18/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.8707 - loss: 0.6137 - val_accuracy: 0.8194 - val_loss: 1.1603\n",
            "Epoch 19/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8718 - loss: 0.6069 - val_accuracy: 0.8183 - val_loss: 1.1725\n",
            "Epoch 20/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8734 - loss: 0.5991 - val_accuracy: 0.8191 - val_loss: 1.1816\n",
            "Epoch 21/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8751 - loss: 0.5939 - val_accuracy: 0.8187 - val_loss: 1.1934\n",
            "Epoch 22/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8761 - loss: 0.5879 - val_accuracy: 0.8195 - val_loss: 1.1973\n",
            "Epoch 23/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.8771 - loss: 0.5837 - val_accuracy: 0.8185 - val_loss: 1.2092\n",
            "Epoch 24/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8776 - loss: 0.5803 - val_accuracy: 0.8176 - val_loss: 1.2180\n",
            "Epoch 25/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8792 - loss: 0.5752 - val_accuracy: 0.8185 - val_loss: 1.2253\n",
            "Epoch 26/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.8795 - loss: 0.5718 - val_accuracy: 0.8176 - val_loss: 1.2297\n",
            "Epoch 27/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8803 - loss: 0.5684 - val_accuracy: 0.8184 - val_loss: 1.2381\n",
            "Epoch 28/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8803 - loss: 0.5662 - val_accuracy: 0.8175 - val_loss: 1.2462\n",
            "Epoch 29/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8809 - loss: 0.5634 - val_accuracy: 0.8173 - val_loss: 1.2496\n",
            "Epoch 30/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.8809 - loss: 0.5621 - val_accuracy: 0.8179 - val_loss: 1.2528\n",
            "Epoch 31/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8812 - loss: 0.5609 - val_accuracy: 0.8180 - val_loss: 1.2648\n",
            "Epoch 32/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8815 - loss: 0.5598 - val_accuracy: 0.8174 - val_loss: 1.2649\n",
            "Epoch 33/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8817 - loss: 0.5587 - val_accuracy: 0.8173 - val_loss: 1.2720\n",
            "Epoch 34/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8823 - loss: 0.5550 - val_accuracy: 0.8179 - val_loss: 1.2771\n",
            "Epoch 35/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8826 - loss: 0.5545 - val_accuracy: 0.8172 - val_loss: 1.2844\n",
            "Epoch 36/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8827 - loss: 0.5540 - val_accuracy: 0.8180 - val_loss: 1.2920\n",
            "Epoch 37/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8829 - loss: 0.5517 - val_accuracy: 0.8174 - val_loss: 1.2928\n",
            "Epoch 38/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8826 - loss: 0.5510 - val_accuracy: 0.8179 - val_loss: 1.2995\n",
            "Epoch 39/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8834 - loss: 0.5501 - val_accuracy: 0.8168 - val_loss: 1.3067\n",
            "Epoch 40/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8835 - loss: 0.5496 - val_accuracy: 0.8138 - val_loss: 1.3078\n",
            "Epoch 41/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8832 - loss: 0.5509 - val_accuracy: 0.8169 - val_loss: 1.3117\n",
            "Epoch 42/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8835 - loss: 0.5475 - val_accuracy: 0.8180 - val_loss: 1.3126\n",
            "Epoch 43/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8829 - loss: 0.5484 - val_accuracy: 0.8172 - val_loss: 1.3145\n",
            "Epoch 44/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8831 - loss: 0.5483 - val_accuracy: 0.8167 - val_loss: 1.3226\n",
            "Epoch 45/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8837 - loss: 0.5462 - val_accuracy: 0.8169 - val_loss: 1.3286\n",
            "Epoch 46/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.8834 - loss: 0.5466 - val_accuracy: 0.8165 - val_loss: 1.3315\n",
            "Epoch 47/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - accuracy: 0.8839 - loss: 0.5463 - val_accuracy: 0.8175 - val_loss: 1.3295\n",
            "Epoch 48/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8834 - loss: 0.5451 - val_accuracy: 0.8164 - val_loss: 1.3383\n",
            "Epoch 49/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.8834 - loss: 0.5441 - val_accuracy: 0.8165 - val_loss: 1.3432\n",
            "Epoch 50/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8838 - loss: 0.5443 - val_accuracy: 0.8171 - val_loss: 1.3358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
            "\n",
            "🔹Input: zain was hesitant\n",
            "🔹Target:  زین ہچکچا رہا تھا \n",
            "🔹Predicted: میں نے رہا تھا \n",
            "🔹BLEU Score: 0.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\n",
            "🔹Input: did zain give you that\n",
            "🔹Target:  زین نے تمہیں وہ دیا \n",
            "🔹Predicted: میں نے مریم معاف دیا \n",
            "🔹BLEU Score: 0.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\n",
            "🔹Input: i come from china\n",
            "🔹Target:  میں چین سے آیا ہوں۔ \n",
            "🔹Predicted: میں نے سے ہوں ہوں۔ \n",
            "🔹BLEU Score: 0.0000\n",
            "\n",
            "✨ Average BLEU Score: 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "# RNN\n",
        "rnn_model = build_seq2seq_model('rnn')\n",
        "train_model(rnn_model, 'rnn')\n",
        "evaluate_bleu(rnn_model, [10, 20, 30])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Blv3Yv3eWY"
      },
      "source": [
        "**Bi-RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sRFgv3bY3aWS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "def build_bi_rnn_model():\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(max_input_len,))\n",
        "    encoder_embedding = Embedding(VOCAB_SIZE_EN, EMBEDDING_DIM)(encoder_inputs)\n",
        "\n",
        "    # Bidirectional RNN Encoder\n",
        "    encoder_rnn = Bidirectional(SimpleRNN(UNITS, return_state=True))\n",
        "    encoder_outputs, forward_h, backward_h = encoder_rnn(encoder_embedding)\n",
        "    state_h = Concatenate()([forward_h, backward_h])\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(max_target_len,))\n",
        "    decoder_embedding = Embedding(VOCAB_SIZE_UR, EMBEDDING_DIM)(decoder_inputs)\n",
        "\n",
        "    decoder_rnn = SimpleRNN(UNITS * 2, return_sequences=True)\n",
        "    decoder_outputs = decoder_rnn(decoder_embedding, initial_state=[state_h])\n",
        "\n",
        "    decoder_dense = Dense(VOCAB_SIZE_UR, activation='softmax')\n",
        "    output = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwy-gGJp3nwD",
        "outputId": "c49b9805-90f6-4fca-c2e8-afe82066107c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 62ms/step - accuracy: 0.7404 - loss: 1.9111 - val_accuracy: 0.8020 - val_loss: 1.2275\n",
            "Epoch 2/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 49ms/step - accuracy: 0.8120 - loss: 1.1265 - val_accuracy: 0.8360 - val_loss: 0.9898\n",
            "Epoch 3/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.8444 - loss: 0.8610 - val_accuracy: 0.8506 - val_loss: 0.8893\n",
            "Epoch 4/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.8622 - loss: 0.6883 - val_accuracy: 0.8575 - val_loss: 0.8424\n",
            "Epoch 5/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.8766 - loss: 0.5594 - val_accuracy: 0.8634 - val_loss: 0.8200\n",
            "Epoch 6/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.8925 - loss: 0.4506 - val_accuracy: 0.8680 - val_loss: 0.8124\n",
            "Epoch 7/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.9066 - loss: 0.3690 - val_accuracy: 0.8709 - val_loss: 0.8216\n",
            "Epoch 8/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.9208 - loss: 0.2995 - val_accuracy: 0.8730 - val_loss: 0.8285\n",
            "Epoch 9/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.9352 - loss: 0.2388 - val_accuracy: 0.8735 - val_loss: 0.8447\n",
            "Epoch 10/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9458 - loss: 0.1942 - val_accuracy: 0.8768 - val_loss: 0.8495\n",
            "Epoch 11/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.9565 - loss: 0.1540 - val_accuracy: 0.8769 - val_loss: 0.8671\n",
            "Epoch 12/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9637 - loss: 0.1275 - val_accuracy: 0.8760 - val_loss: 0.8844\n",
            "Epoch 13/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9708 - loss: 0.1040 - val_accuracy: 0.8775 - val_loss: 0.9042\n",
            "Epoch 14/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9756 - loss: 0.0880 - val_accuracy: 0.8774 - val_loss: 0.9241\n",
            "Epoch 15/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 0.9794 - loss: 0.0739 - val_accuracy: 0.8770 - val_loss: 0.9422\n",
            "Epoch 16/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9807 - loss: 0.0687 - val_accuracy: 0.8778 - val_loss: 0.9574\n",
            "Epoch 17/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9819 - loss: 0.0650 - val_accuracy: 0.8762 - val_loss: 0.9932\n",
            "Epoch 18/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.9811 - loss: 0.0657 - val_accuracy: 0.8769 - val_loss: 1.0074\n",
            "Epoch 19/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9820 - loss: 0.0617 - val_accuracy: 0.8765 - val_loss: 1.0293\n",
            "Epoch 20/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9803 - loss: 0.0654 - val_accuracy: 0.8762 - val_loss: 1.0462\n",
            "Epoch 21/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9820 - loss: 0.0615 - val_accuracy: 0.8767 - val_loss: 1.0704\n",
            "Epoch 22/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9808 - loss: 0.0627 - val_accuracy: 0.8749 - val_loss: 1.0871\n",
            "Epoch 23/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.9810 - loss: 0.0621 - val_accuracy: 0.8755 - val_loss: 1.1060\n",
            "Epoch 24/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9821 - loss: 0.0585 - val_accuracy: 0.8760 - val_loss: 1.1177\n",
            "Epoch 25/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9832 - loss: 0.0547 - val_accuracy: 0.8759 - val_loss: 1.1363\n",
            "Epoch 26/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9827 - loss: 0.0562 - val_accuracy: 0.8766 - val_loss: 1.1453\n",
            "Epoch 27/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9823 - loss: 0.0564 - val_accuracy: 0.8763 - val_loss: 1.1616\n",
            "Epoch 28/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.9809 - loss: 0.0606 - val_accuracy: 0.8742 - val_loss: 1.1837\n",
            "Epoch 29/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9822 - loss: 0.0568 - val_accuracy: 0.8748 - val_loss: 1.2006\n",
            "Epoch 30/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9831 - loss: 0.0542 - val_accuracy: 0.8750 - val_loss: 1.2061\n",
            "Epoch 31/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9837 - loss: 0.0524 - val_accuracy: 0.8740 - val_loss: 1.2236\n",
            "Epoch 32/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 0.9827 - loss: 0.0560 - val_accuracy: 0.8756 - val_loss: 1.2225\n",
            "Epoch 33/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9816 - loss: 0.0581 - val_accuracy: 0.8755 - val_loss: 1.2363\n",
            "Epoch 34/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.9828 - loss: 0.0543 - val_accuracy: 0.8741 - val_loss: 1.2572\n",
            "Epoch 35/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9823 - loss: 0.0560 - val_accuracy: 0.8735 - val_loss: 1.2779\n",
            "Epoch 36/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9825 - loss: 0.0560 - val_accuracy: 0.8739 - val_loss: 1.2756\n",
            "Epoch 37/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9826 - loss: 0.0554 - val_accuracy: 0.8726 - val_loss: 1.3026\n",
            "Epoch 38/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.9812 - loss: 0.0581 - val_accuracy: 0.8739 - val_loss: 1.3051\n",
            "Epoch 39/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9820 - loss: 0.0572 - val_accuracy: 0.8733 - val_loss: 1.3137\n",
            "Epoch 40/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.9810 - loss: 0.0596 - val_accuracy: 0.8733 - val_loss: 1.3258\n",
            "Epoch 41/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9811 - loss: 0.0593 - val_accuracy: 0.8738 - val_loss: 1.3305\n",
            "Epoch 42/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9803 - loss: 0.0625 - val_accuracy: 0.8751 - val_loss: 1.3348\n",
            "Epoch 43/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 0.9812 - loss: 0.0584 - val_accuracy: 0.8739 - val_loss: 1.3440\n",
            "Epoch 44/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.9805 - loss: 0.0614 - val_accuracy: 0.8740 - val_loss: 1.3410\n",
            "Epoch 45/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.9812 - loss: 0.0577 - val_accuracy: 0.8727 - val_loss: 1.3637\n",
            "Epoch 46/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.9812 - loss: 0.0594 - val_accuracy: 0.8738 - val_loss: 1.3691\n",
            "Epoch 47/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9808 - loss: 0.0592 - val_accuracy: 0.8731 - val_loss: 1.3692\n",
            "Epoch 48/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9806 - loss: 0.0608 - val_accuracy: 0.8730 - val_loss: 1.3910\n",
            "Epoch 49/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.9819 - loss: 0.0565 - val_accuracy: 0.8737 - val_loss: 1.3916\n",
            "Epoch 50/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.9806 - loss: 0.0608 - val_accuracy: 0.8728 - val_loss: 1.3947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988ms/step\n",
            "\n",
            "🔹Input: zain was hesitant\n",
            "🔹Target:  زین ہچکچا رہا تھا \n",
            "🔹Predicted: زین ہچکچا رہا تھا \n",
            "🔹BLEU Score: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "🔹Input: did zain give you that\n",
            "🔹Target:  زین نے تمہیں وہ دیا \n",
            "🔹Predicted: زین نے تمہیں وہ دیا \n",
            "🔹BLEU Score: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\n",
            "🔹Input: i come from china\n",
            "🔹Target:  میں چین سے آیا ہوں۔ \n",
            "🔹Predicted: میں چین سے آیا ہوں۔ \n",
            "🔹BLEU Score: 1.0000\n",
            "\n",
            "✨ Average BLEU Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Build and train the Bi-RNN model\n",
        "bi_rnn_model = build_bi_rnn_model()\n",
        "train_model(bi_rnn_model, 'bi_rnn')\n",
        "\n",
        "# Evaluate the Bi-RNN model with BLEU scores\n",
        "evaluate_bleu(bi_rnn_model, [10, 20, 30])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olTmCya63ruj"
      },
      "source": [
        "**LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_e9b8XBV3tjS"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model():\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(max_input_len,))\n",
        "    encoder_embedding = Embedding(VOCAB_SIZE_EN, EMBEDDING_DIM)(encoder_inputs)\n",
        "\n",
        "    # Encoder LSTM\n",
        "    encoder_lstm = LSTM(UNITS, return_state=True)\n",
        "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(max_target_len,))\n",
        "    decoder_embedding = Embedding(VOCAB_SIZE_UR, EMBEDDING_DIM)(decoder_inputs)\n",
        "\n",
        "    decoder_lstm = LSTM(UNITS, return_sequences=True)\n",
        "    decoder_outputs = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "    decoder_dense = Dense(VOCAB_SIZE_UR, activation='softmax')\n",
        "    output = decoder_dense(decoder_outputs)\n",
        "\n",
        "    model = Model([encoder_inputs, decoder_inputs], output)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpOINdxg3wE2",
        "outputId": "66bff057-b9df-4d23-9621-c871118a7c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.7342 - loss: 2.1701 - val_accuracy: 0.7863 - val_loss: 1.3118\n",
            "Epoch 2/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.7934 - loss: 1.2405 - val_accuracy: 0.8097 - val_loss: 1.1465\n",
            "Epoch 3/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.8157 - loss: 1.0705 - val_accuracy: 0.8277 - val_loss: 1.0324\n",
            "Epoch 4/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.8347 - loss: 0.9302 - val_accuracy: 0.8419 - val_loss: 0.9422\n",
            "Epoch 5/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.8499 - loss: 0.8147 - val_accuracy: 0.8527 - val_loss: 0.8740\n",
            "Epoch 6/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.8630 - loss: 0.7115 - val_accuracy: 0.8609 - val_loss: 0.8204\n",
            "Epoch 7/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.8749 - loss: 0.6216 - val_accuracy: 0.8665 - val_loss: 0.7758\n",
            "Epoch 8/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.8857 - loss: 0.5394 - val_accuracy: 0.8731 - val_loss: 0.7412\n",
            "Epoch 9/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.8982 - loss: 0.4608 - val_accuracy: 0.8786 - val_loss: 0.7119\n",
            "Epoch 10/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.9112 - loss: 0.3878 - val_accuracy: 0.8835 - val_loss: 0.6893\n",
            "Epoch 11/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.9248 - loss: 0.3229 - val_accuracy: 0.8882 - val_loss: 0.6692\n",
            "Epoch 12/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9372 - loss: 0.2659 - val_accuracy: 0.8906 - val_loss: 0.6636\n",
            "Epoch 13/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - accuracy: 0.9500 - loss: 0.2144 - val_accuracy: 0.8944 - val_loss: 0.6500\n",
            "Epoch 14/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.9610 - loss: 0.1716 - val_accuracy: 0.8949 - val_loss: 0.6529\n",
            "Epoch 15/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.9702 - loss: 0.1361 - val_accuracy: 0.8959 - val_loss: 0.6559\n",
            "Epoch 16/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9777 - loss: 0.1075 - val_accuracy: 0.8971 - val_loss: 0.6592\n",
            "Epoch 17/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9840 - loss: 0.0841 - val_accuracy: 0.8989 - val_loss: 0.6635\n",
            "Epoch 18/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.9885 - loss: 0.0656 - val_accuracy: 0.8985 - val_loss: 0.6746\n",
            "Epoch 19/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9920 - loss: 0.0509 - val_accuracy: 0.8995 - val_loss: 0.6792\n",
            "Epoch 20/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9940 - loss: 0.0404 - val_accuracy: 0.9002 - val_loss: 0.6889\n",
            "Epoch 21/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.9957 - loss: 0.0316 - val_accuracy: 0.9000 - val_loss: 0.6987\n",
            "Epoch 22/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9970 - loss: 0.0247 - val_accuracy: 0.9001 - val_loss: 0.7066\n",
            "Epoch 23/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.9976 - loss: 0.0197 - val_accuracy: 0.8999 - val_loss: 0.7214\n",
            "Epoch 24/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9982 - loss: 0.0167 - val_accuracy: 0.9008 - val_loss: 0.7263\n",
            "Epoch 25/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.9984 - loss: 0.0142 - val_accuracy: 0.9004 - val_loss: 0.7347\n",
            "Epoch 26/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.9986 - loss: 0.0130 - val_accuracy: 0.8992 - val_loss: 0.7533\n",
            "Epoch 27/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.9986 - loss: 0.0120 - val_accuracy: 0.9002 - val_loss: 0.7582\n",
            "Epoch 28/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9982 - loss: 0.0130 - val_accuracy: 0.9005 - val_loss: 0.7590\n",
            "Epoch 29/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 51ms/step - accuracy: 0.9984 - loss: 0.0118 - val_accuracy: 0.8989 - val_loss: 0.7733\n",
            "Epoch 30/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9982 - loss: 0.0121 - val_accuracy: 0.9006 - val_loss: 0.7729\n",
            "Epoch 31/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.9988 - loss: 0.0093 - val_accuracy: 0.9008 - val_loss: 0.7821\n",
            "Epoch 32/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.9992 - loss: 0.0068 - val_accuracy: 0.9006 - val_loss: 0.8001\n",
            "Epoch 33/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9993 - loss: 0.0059 - val_accuracy: 0.9014 - val_loss: 0.8014\n",
            "Epoch 34/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.9993 - loss: 0.0052 - val_accuracy: 0.9000 - val_loss: 0.8175\n",
            "Epoch 35/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9992 - loss: 0.0056 - val_accuracy: 0.8998 - val_loss: 0.8249\n",
            "Epoch 36/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.9981 - loss: 0.0099 - val_accuracy: 0.8985 - val_loss: 0.8352\n",
            "Epoch 37/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9956 - loss: 0.0188 - val_accuracy: 0.8985 - val_loss: 0.8311\n",
            "Epoch 38/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9977 - loss: 0.0115 - val_accuracy: 0.9003 - val_loss: 0.8295\n",
            "Epoch 39/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.9991 - loss: 0.0055 - val_accuracy: 0.9020 - val_loss: 0.8290\n",
            "Epoch 40/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9017 - val_loss: 0.8418\n",
            "Epoch 41/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9028 - val_loss: 0.8401\n",
            "Epoch 42/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.9026 - val_loss: 0.8405\n",
            "Epoch 43/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9021 - val_loss: 0.8522\n",
            "Epoch 44/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 52ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9021 - val_loss: 0.8523\n",
            "Epoch 45/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9023 - val_loss: 0.8683\n",
            "Epoch 46/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.8988 - val_loss: 0.8686\n",
            "Epoch 47/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.9911 - loss: 0.0315 - val_accuracy: 0.8971 - val_loss: 0.8601\n",
            "Epoch 48/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9947 - loss: 0.0194 - val_accuracy: 0.9000 - val_loss: 0.8584\n",
            "Epoch 49/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.9990 - loss: 0.0059 - val_accuracy: 0.9015 - val_loss: 0.8603\n",
            "Epoch 50/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 52ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9023 - val_loss: 0.8630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\n",
            "🔹Input: zain was hesitant\n",
            "🔹Target:  زین ہچکچا رہا تھا \n",
            "🔹Predicted: زین ہچکچا رہا تھا \n",
            "🔹BLEU Score: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\n",
            "🔹Input: did zain give you that\n",
            "🔹Target:  زین نے تمہیں وہ دیا \n",
            "🔹Predicted: زین نے تمہیں وہ دیا \n",
            "🔹BLEU Score: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\n",
            "🔹Input: i come from china\n",
            "🔹Target:  میں چین سے آیا ہوں۔ \n",
            "🔹Predicted: میں چین سے آیا ہوں۔ \n",
            "🔹BLEU Score: 1.0000\n",
            "\n",
            "✨ Average BLEU Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Build and train the LSTM model\n",
        "lstm_model = build_lstm_model()\n",
        "train_model(lstm_model, 'lstm')\n",
        "\n",
        "# Evaluate the LSTM model with BLEU scores\n",
        "evaluate_bleu(lstm_model, [10, 20, 30])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh6-ySCt4r8S"
      },
      "source": [
        "**TRANSFORMER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "360_s1uD4udi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, position, d_model):\n",
        "        super().__init__()\n",
        "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"position\": self.pos_encoding.shape[0], \"d_model\": self.pos_encoding.shape[1]}\n",
        "\n",
        "    def positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            np.arange(position)[:, np.newaxis],\n",
        "            np.arange(d_model)[np.newaxis, :],\n",
        "            d_model)\n",
        "        # apply sin to even indices and cos to odd indices\n",
        "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "        pos_encoding = angle_rads[np.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        return pos / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nRwpRl8v4xIS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, Embedding, LayerNormalization,\n",
        "    MultiHeadAttention, Add\n",
        ")\n",
        "\n",
        "def transformer_encoder_layer(embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "    inputs = Input(shape=(None, embed_dim))\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
        "    attn_output = Dropout(rate)(attn_output)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(Add()([inputs, attn_output]))\n",
        "\n",
        "    ffn = Dense(ff_dim, activation='relu')(out1)\n",
        "    ffn = Dense(embed_dim)(ffn)\n",
        "    ffn_output = Dropout(rate)(ffn)\n",
        "    out2 = LayerNormalization(epsilon=1e-6)(Add()([out1, ffn_output]))\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=out2)\n",
        "\n",
        "def transformer_decoder_layer(embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "    inputs = Input(shape=(None, embed_dim))\n",
        "    enc_output = Input(shape=(None, embed_dim))\n",
        "\n",
        "    attn1 = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
        "    attn1 = Dropout(rate)(attn1)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(Add()([inputs, attn1]))\n",
        "\n",
        "    attn2 = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(out1, enc_output)\n",
        "    attn2 = Dropout(rate)(attn2)\n",
        "    out2 = LayerNormalization(epsilon=1e-6)(Add()([out1, attn2]))\n",
        "\n",
        "    ffn = Dense(ff_dim, activation='relu')(out2)\n",
        "    ffn = Dense(embed_dim)(ffn)\n",
        "    ffn_output = Dropout(rate)(ffn)\n",
        "    out3 = LayerNormalization(epsilon=1e-6)(Add()([out2, ffn_output]))\n",
        "\n",
        "    return tf.keras.Model(inputs=[inputs, enc_output], outputs=out3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8z59z0Nc4zT2"
      },
      "outputs": [],
      "source": [
        "def build_transformer_model():\n",
        "    embed_dim = EMBEDDING_DIM\n",
        "    ff_dim = 512\n",
        "    num_heads = 4\n",
        "    dropout_rate = 0.1\n",
        "\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(max_input_len,))\n",
        "    x = Embedding(VOCAB_SIZE_EN, embed_dim)(encoder_inputs)\n",
        "    x = PositionalEncoding(max_input_len, embed_dim)(x)\n",
        "    encoder_layer = transformer_encoder_layer(embed_dim, num_heads, ff_dim, dropout_rate)\n",
        "    encoder_output = encoder_layer(x)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(max_target_len,))\n",
        "    y = Embedding(VOCAB_SIZE_UR, embed_dim)(decoder_inputs)\n",
        "    y = PositionalEncoding(max_target_len, embed_dim)(y)\n",
        "    decoder_layer = transformer_decoder_layer(embed_dim, num_heads, ff_dim, dropout_rate)\n",
        "    decoder_output = decoder_layer([y, encoder_output])\n",
        "\n",
        "    final_output = Dense(VOCAB_SIZE_UR, activation='softmax')(decoder_output)\n",
        "\n",
        "    model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=final_output)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITsGDA5J44Yw",
        "outputId": "40ca31fd-0d11-4677-a65d-4b9a4f5d658c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 86ms/step - accuracy: 0.7360 - loss: 2.2419 - val_accuracy: 0.8544 - val_loss: 0.9484\n",
            "Epoch 2/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.8967 - loss: 0.6842 - val_accuracy: 0.9649 - val_loss: 0.2598\n",
            "Epoch 3/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9719 - loss: 0.2003 - val_accuracy: 0.9816 - val_loss: 0.1492\n",
            "Epoch 4/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.9869 - loss: 0.0923 - val_accuracy: 0.9868 - val_loss: 0.1189\n",
            "Epoch 5/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.9921 - loss: 0.0527 - val_accuracy: 0.9889 - val_loss: 0.1069\n",
            "Epoch 6/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9954 - loss: 0.0288 - val_accuracy: 0.9903 - val_loss: 0.1034\n",
            "Epoch 7/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9981 - loss: 0.0145 - val_accuracy: 0.9904 - val_loss: 0.1059\n",
            "Epoch 8/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9993 - loss: 0.0079 - val_accuracy: 0.9913 - val_loss: 0.1022\n",
            "Epoch 9/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9999 - loss: 0.0023 - val_accuracy: 0.9916 - val_loss: 0.1041\n",
            "Epoch 10/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9919 - val_loss: 0.1041\n",
            "Epoch 11/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 6.8805e-04 - val_accuracy: 0.9920 - val_loss: 0.1064\n",
            "Epoch 12/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.9949 - loss: 0.0436 - val_accuracy: 0.7144 - val_loss: 2.1472\n",
            "Epoch 13/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.7505 - loss: 1.6739 - val_accuracy: 0.7620 - val_loss: 1.6755\n",
            "Epoch 14/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.8468 - loss: 0.9620 - val_accuracy: 0.9237 - val_loss: 0.3494\n",
            "Epoch 15/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9914 - loss: 0.0450 - val_accuracy: 0.9900 - val_loss: 0.1043\n",
            "Epoch 16/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9971 - loss: 0.0165 - val_accuracy: 0.9777 - val_loss: 0.1727\n",
            "Epoch 17/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9994 - loss: 0.0064 - val_accuracy: 0.9816 - val_loss: 0.1666\n",
            "Epoch 18/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - accuracy: 0.9998 - loss: 0.0027 - val_accuracy: 0.9813 - val_loss: 0.1576\n",
            "Epoch 19/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 0.9906 - val_loss: 0.1276\n",
            "Epoch 20/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9890 - val_loss: 0.1379\n",
            "Epoch 21/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9892 - val_loss: 0.1323\n",
            "Epoch 22/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9928 - val_loss: 0.1176\n",
            "Epoch 23/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9927 - val_loss: 0.1208\n",
            "Epoch 24/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9998 - loss: 0.0030 - val_accuracy: 0.9900 - val_loss: 0.1345\n",
            "Epoch 25/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9392 - loss: 0.3994 - val_accuracy: 0.9877 - val_loss: 0.1094\n",
            "Epoch 26/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9904 - loss: 0.0436 - val_accuracy: 0.9908 - val_loss: 0.1196\n",
            "Epoch 27/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9981 - loss: 0.0090 - val_accuracy: 0.9924 - val_loss: 0.1129\n",
            "Epoch 28/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9997 - loss: 0.0035 - val_accuracy: 0.9926 - val_loss: 0.1202\n",
            "Epoch 29/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 0.0023 - val_accuracy: 0.9928 - val_loss: 0.1160\n",
            "Epoch 30/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 5.6960e-04 - val_accuracy: 0.9924 - val_loss: 0.1237\n",
            "Epoch 31/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.9928 - val_loss: 0.1219\n",
            "Epoch 32/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9928 - val_loss: 0.1259\n",
            "Epoch 33/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 6.0945e-04 - val_accuracy: 0.9929 - val_loss: 0.1184\n",
            "Epoch 34/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9997 - loss: 0.0044 - val_accuracy: 0.9929 - val_loss: 0.1242\n",
            "Epoch 35/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.0089e-04 - val_accuracy: 0.9928 - val_loss: 0.1255\n",
            "Epoch 36/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.0200e-04 - val_accuracy: 0.9929 - val_loss: 0.1248\n",
            "Epoch 37/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 3.6297e-04 - val_accuracy: 0.9929 - val_loss: 0.1257\n",
            "Epoch 38/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 3.2786e-04 - val_accuracy: 0.9928 - val_loss: 0.1322\n",
            "Epoch 39/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.8633e-04 - val_accuracy: 0.9929 - val_loss: 0.1310\n",
            "Epoch 40/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.9623e-04 - val_accuracy: 0.9927 - val_loss: 0.1382\n",
            "Epoch 41/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9989 - loss: 0.0057 - val_accuracy: 0.9921 - val_loss: 0.1472\n",
            "Epoch 42/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9920 - val_loss: 0.1576\n",
            "Epoch 43/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9994 - loss: 0.0035 - val_accuracy: 0.9923 - val_loss: 0.1602\n",
            "Epoch 44/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9926 - val_loss: 0.1697\n",
            "Epoch 45/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 6.5216e-04 - val_accuracy: 0.9928 - val_loss: 0.1607\n",
            "Epoch 46/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.0262e-04 - val_accuracy: 0.9927 - val_loss: 0.1661\n",
            "Epoch 47/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - accuracy: 0.9999 - loss: 7.0850e-04 - val_accuracy: 0.9928 - val_loss: 0.1643\n",
            "Epoch 48/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.1318e-04 - val_accuracy: 0.9927 - val_loss: 0.1709\n",
            "Epoch 49/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 2.8066e-04 - val_accuracy: 0.9929 - val_loss: 0.1642\n",
            "Epoch 50/50\n",
            "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9925 - val_loss: 0.1752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\n",
            "🔹Input: zain was hesitant\n",
            "🔹Target:  زین ہچکچا رہا تھا \n",
            "🔹Predicted: زین ہچکچا رہا تھا \n",
            "🔹BLEU Score: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "🔹Input: did zain give you that\n",
            "🔹Target:  زین نے تمہیں وہ دیا \n",
            "🔹Predicted: زین نے تمہیں وہ دیا \n",
            "🔹BLEU Score: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "🔹Input: i come from china\n",
            "🔹Target:  میں چین سے آیا ہوں۔ \n",
            "🔹Predicted: میں چین سے آیا ہوں۔ \n",
            "🔹BLEU Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Build and train the Transformer model\n",
        "transformer_model = build_transformer_model()\n",
        "train_model(transformer_model, 'transformer')\n",
        "\n",
        "# Evaluate the Transformer model with BLEU scores\n",
        "evaluate_bleu(transformer_model, [10, 20, 30])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
