{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1) Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:01:48.498589Z",
     "iopub.status.busy": "2025-04-20T15:01:48.498058Z",
     "iopub.status.idle": "2025-04-20T15:01:48.607480Z",
     "shell.execute_reply": "2025-04-20T15:01:48.607002Z",
     "shell.execute_reply.started": "2025-04-20T15:01:48.498569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For deep learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Bidirectional, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:16:00.849339Z",
     "iopub.status.busy": "2025-04-20T14:16:00.848676Z",
     "iopub.status.idle": "2025-04-20T14:16:03.881968Z",
     "shell.execute_reply": "2025-04-20T14:16:03.881128Z",
     "shell.execute_reply.started": "2025-04-20T14:16:00.849310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For transformers (BERT, XLM-R)\n",
    "!pip install -q transformers\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import XLMRobertaTokenizer, TFXLMRobertaForSequenceClassification\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:15:14.379216Z",
     "iopub.status.busy": "2025-04-20T14:15:14.378587Z",
     "iopub.status.idle": "2025-04-20T14:15:14.428124Z",
     "shell.execute_reply": "2025-04-20T14:15:14.427561Z",
     "shell.execute_reply.started": "2025-04-20T14:15:14.379195Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/urduuusentiment/urdu-sentiment-corpus-v1.tsv', sep='\\t')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:15:17.558010Z",
     "iopub.status.busy": "2025-04-20T14:15:17.557500Z",
     "iopub.status.idle": "2025-04-20T14:15:17.567740Z",
     "shell.execute_reply": "2025-04-20T14:15:17.566973Z",
     "shell.execute_reply.started": "2025-04-20T14:15:17.557985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "N    499\n",
      "P    480\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے ه...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
       "2  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
       "3    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P\n",
       "4   گندی زبان اور گٹر جیسے دماغ والے جاهل جیالے ه...     N"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"Other\" (O) classes because we want only P and N\n",
    "df = df[df['Class'].isin(['P', 'N'])]\n",
    "\n",
    "# Reset index (optional)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Check\n",
    "print(df['Class'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:15:20.139272Z",
     "iopub.status.busy": "2025-04-20T14:15:20.139008Z",
     "iopub.status.idle": "2025-04-20T14:15:20.144738Z",
     "shell.execute_reply": "2025-04-20T14:15:20.144037Z",
     "shell.execute_reply.started": "2025-04-20T14:15:20.139254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode labels: P -> 1, N -> 0\n",
    "df['label'] = df['Class'].map({'P': 1, 'N': 0})\n",
    "\n",
    "# Separate texts and labels\n",
    "texts = df['Tweet'].values\n",
    "labels = df['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:15:24.113880Z",
     "iopub.status.busy": "2025-04-20T14:15:24.113392Z",
     "iopub.status.idle": "2025-04-20T14:15:24.120401Z",
     "shell.execute_reply": "2025-04-20T14:15:24.119797Z",
     "shell.execute_reply.started": "2025-04-20T14:15:24.113857Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 734\n",
      "Testing samples: 245\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.25, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:09:17.378490Z",
     "iopub.status.busy": "2025-04-20T11:09:17.377799Z",
     "iopub.status.idle": "2025-04-20T11:09:17.388287Z",
     "shell.execute_reply": "2025-04-20T11:09:17.387522Z",
     "shell.execute_reply.started": "2025-04-20T11:09:17.378450Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tweet length: 17.569482288828336\n",
      "95th percentile length: 30.0\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(text.split()) for text in X_train]\n",
    "print(f\"Average tweet length: {np.mean(lengths)}\")\n",
    "print(f\"95th percentile length: {np.percentile(lengths, 95)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:09:32.561118Z",
     "iopub.status.busy": "2025-04-20T11:09:32.560566Z",
     "iopub.status.idle": "2025-04-20T11:09:32.567865Z",
     "shell.execute_reply": "2025-04-20T11:09:32.567051Z",
     "shell.execute_reply.started": "2025-04-20T11:09:32.561096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 4617\n"
     ]
    }
   ],
   "source": [
    "all_text = ' '.join(X_train)\n",
    "unique_words = set(all_text.split())\n",
    "print(f\"Total unique words: {len(unique_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:16:06.035873Z",
     "iopub.status.busy": "2025-04-20T14:16:06.035083Z",
     "iopub.status.idle": "2025-04-20T14:16:06.098034Z",
     "shell.execute_reply": "2025-04-20T14:16:06.097498Z",
     "shell.execute_reply.started": "2025-04-20T14:16:06.035842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "vocab_size = 10000  \n",
    "max_length = 50  \n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Sequence Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RNN Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:12:14.385757Z",
     "iopub.status.busy": "2025-04-20T11:12:14.385414Z",
     "iopub.status.idle": "2025-04-20T11:12:14.390597Z",
     "shell.execute_reply": "2025-04-20T11:12:14.389690Z",
     "shell.execute_reply.started": "2025-04-20T11:12:14.385734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_rnn_model(vocab_size, max_length):\n",
    "    model = Sequential()\n",
    "    # Embedding layer with proper input shape\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length))\n",
    "    model.add(SimpleRNN(64, return_sequences=False))  # Simple RNN layer\n",
    "    model.add(Dropout(0.5))  # Dropout for regularization\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid for binary classification\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # Compilation\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:14:00.149558Z",
     "iopub.status.busy": "2025-04-20T11:14:00.148893Z",
     "iopub.status.idle": "2025-04-20T11:14:03.508379Z",
     "shell.execute_reply": "2025-04-20T11:14:03.507829Z",
     "shell.execute_reply.started": "2025-04-20T11:14:00.149534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.5306 - val_loss: 1.9161\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0060 - val_accuracy: 0.5306 - val_loss: 2.0603\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0020 - val_accuracy: 0.5265 - val_loss: 1.9886\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.5347 - val_loss: 1.9757\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.5184 - val_loss: 1.9692\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.5265 - val_loss: 2.0104\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0026 - val_accuracy: 0.5265 - val_loss: 1.9700\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.4898 - val_loss: 2.1065\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.0556e-04 - val_accuracy: 0.5388 - val_loss: 2.0131\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.5184 - val_loss: 2.0279\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0043 - val_accuracy: 0.5061 - val_loss: 2.0611\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0026 - val_accuracy: 0.5347 - val_loss: 2.0155\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0075 - val_accuracy: 0.5143 - val_loss: 1.9087\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.5469 - val_loss: 2.0075\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0018 - val_accuracy: 0.5347 - val_loss: 2.0438\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0091 - val_accuracy: 0.5102 - val_loss: 2.0061\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.0084 - val_accuracy: 0.5184 - val_loss: 2.0076\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.5224 - val_loss: 2.0713\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0032 - val_accuracy: 0.4898 - val_loss: 2.1647\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0026 - val_accuracy: 0.4939 - val_loss: 2.1299\n"
     ]
    }
   ],
   "source": [
    "# Train Simple RNN\n",
    "history = rnn_model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_pad, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:14:05.903698Z",
     "iopub.status.busy": "2025-04-20T11:14:05.903404Z",
     "iopub.status.idle": "2025-04-20T11:14:05.995255Z",
     "shell.execute_reply": "2025-04-20T11:14:05.994442Z",
     "shell.execute_reply.started": "2025-04-20T11:14:05.903678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Simple RNN Results:\n",
      "Accuracy: 0.49387755102040815\n",
      "Precision: 0.4852941176470588\n",
      "Recall: 0.55\n",
      "F1 Score: 0.5156249999999999\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred_rnn = (rnn_model.predict(X_test_pad) > 0.5).astype('int32')\n",
    "\n",
    "# Metrics\n",
    "print(\"Simple RNN Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rnn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rnn))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rnn))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rnn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning for RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:19:07.353547Z",
     "iopub.status.busy": "2025-04-20T11:19:07.353208Z",
     "iopub.status.idle": "2025-04-20T11:19:10.336147Z",
     "shell.execute_reply": "2025-04-20T11:19:10.335158Z",
     "shell.execute_reply.started": "2025-04-20T11:19:07.353508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:19:18.843682Z",
     "iopub.status.busy": "2025-04-20T11:19:18.842988Z",
     "iopub.status.idle": "2025-04-20T11:19:19.209977Z",
     "shell.execute_reply": "2025-04-20T11:19:19.209214Z",
     "shell.execute_reply.started": "2025-04-20T11:19:18.843653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dropout, Dense, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define model-building function with tunable hyperparameters\n",
    "def build_rnn_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tune the embedding output dimension\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=hp.Int('embedding_dim', min_value=64, max_value=256, step=64), \n",
    "                        input_length=max_length))\n",
    "    \n",
    "    # Tune RNN units and add BiRNN\n",
    "    model.add(Bidirectional(SimpleRNN(\n",
    "        units=hp.Int('rnn_units', min_value=64, max_value=256, step=64), \n",
    "        return_sequences=False)))\n",
    "    \n",
    "    # Tune dropout rate\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model with tunable learning rate\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:19:27.865595Z",
     "iopub.status.busy": "2025-04-20T11:19:27.865260Z",
     "iopub.status.idle": "2025-04-20T11:22:18.502611Z",
     "shell.execute_reply": "2025-04-20T11:22:18.501970Z",
     "shell.execute_reply.started": "2025-04-20T11:19:27.865571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 34s]\n",
      "val_accuracy: 0.5646258393923441\n",
      "\n",
      "Best val_accuracy So Far: 0.5646258393923441\n",
      "Total elapsed time: 00h 02m 51s\n",
      "Best Hyperparameters: <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7dd43836a650>\n"
     ]
    }
   ],
   "source": [
    "# Define the Hyperparameter tuner using RandomSearch or Hyperband\n",
    "tuner = kt.RandomSearch(\n",
    "    build_rnn_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of models to try\n",
    "    executions_per_trial=3,  # Number of models to run for each trial\n",
    "    directory='rnn_tuning',\n",
    "    project_name='rnn_hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Perform the search using the training data\n",
    "tuner.search(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:23:37.785156Z",
     "iopub.status.busy": "2025-04-20T11:23:37.784369Z",
     "iopub.status.idle": "2025-04-20T11:23:52.218045Z",
     "shell.execute_reply": "2025-04-20T11:23:52.217105Z",
     "shell.execute_reply.started": "2025-04-20T11:23:37.785128Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 120ms/step - accuracy: 0.5302 - loss: 0.6885 - val_accuracy: 0.4857 - val_loss: 0.7026\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6014 - loss: 0.6718 - val_accuracy: 0.5061 - val_loss: 0.6976\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7102 - loss: 0.6350 - val_accuracy: 0.4816 - val_loss: 0.7008\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8571 - loss: 0.5486 - val_accuracy: 0.4939 - val_loss: 0.7155\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9288 - loss: 0.4008 - val_accuracy: 0.5102 - val_loss: 0.7569\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9673 - loss: 0.2401 - val_accuracy: 0.5429 - val_loss: 0.7720\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9922 - loss: 0.1265 - val_accuracy: 0.5224 - val_loss: 0.8181\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0796 - val_accuracy: 0.5020 - val_loss: 0.8844\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0560 - val_accuracy: 0.4939 - val_loss: 0.9029\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0372 - val_accuracy: 0.4857 - val_loss: 0.9592\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0273 - val_accuracy: 0.4980 - val_loss: 1.0294\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0246 - val_accuracy: 0.4939 - val_loss: 0.9982\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9981 - loss: 0.0182 - val_accuracy: 0.4816 - val_loss: 1.0135\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0159 - val_accuracy: 0.4735 - val_loss: 1.0186\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.4694 - val_loss: 1.0177\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0102 - val_accuracy: 0.4939 - val_loss: 1.0590\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0132 - val_accuracy: 0.4898 - val_loss: 1.0649\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9981 - loss: 0.0088 - val_accuracy: 0.4857 - val_loss: 1.0865\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 0.4857 - val_loss: 1.1081\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0081 - val_accuracy: 0.4816 - val_loss: 1.1287\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n",
      "Best Model Results:\n",
      "Accuracy: 0.4816326530612245\n",
      "Precision: 0.4785276073619632\n",
      "Recall: 0.65\n",
      "F1 Score: 0.5512367491166078\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "history = best_model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_pad, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_best = (best_model.predict(X_test_pad) > 0.5).astype('int32')\n",
    "\n",
    "# Metrics\n",
    "print(\"Best Model Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_best))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_best))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:37:33.075136Z",
     "iopub.status.busy": "2025-04-20T11:37:33.074381Z",
     "iopub.status.idle": "2025-04-20T11:37:33.080978Z",
     "shell.execute_reply": "2025-04-20T11:37:33.080185Z",
     "shell.execute_reply.started": "2025-04-20T11:37:33.075111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model-building function for GRU with tunable hyperparameters\n",
    "def build_gru_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tune the embedding output dimension\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=hp.Int('embedding_dim', min_value=64, max_value=256, step=64), \n",
    "                        input_length=max_length))\n",
    "    \n",
    "    # Tune GRU units and add Bidirectional GRU\n",
    "    model.add(Bidirectional(GRU(\n",
    "        units=hp.Int('gru_units', min_value=64, max_value=256, step=64), \n",
    "        return_sequences=False)))\n",
    "    \n",
    "    # Tune dropout rate\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model with tunable learning rate\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:37:54.981549Z",
     "iopub.status.busy": "2025-04-20T11:37:54.981028Z",
     "iopub.status.idle": "2025-04-20T11:39:45.592273Z",
     "shell.execute_reply": "2025-04-20T11:39:45.591689Z",
     "shell.execute_reply.started": "2025-04-20T11:37:54.981525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 21s]\n",
      "val_accuracy: 0.6108843485514323\n",
      "\n",
      "Best val_accuracy So Far: 0.6108843485514323\n",
      "Total elapsed time: 00h 01m 51s\n",
      "Best GRU Hyperparameters: <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7dd438f62c90>\n"
     ]
    }
   ],
   "source": [
    "# Define the Hyperparameter tuner for GRU model using RandomSearch\n",
    "gru_tuner = kt.RandomSearch(\n",
    "    build_gru_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of models to try\n",
    "    executions_per_trial=3,  # Number of models to run for each trial\n",
    "    directory='gru_tuning',\n",
    "    project_name='gru_hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Perform the search using the training data\n",
    "gru_tuner.search(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_gru_hps = gru_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best GRU Hyperparameters: {best_gru_hps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:40:28.016358Z",
     "iopub.status.busy": "2025-04-20T11:40:28.015476Z",
     "iopub.status.idle": "2025-04-20T11:40:36.427051Z",
     "shell.execute_reply": "2025-04-20T11:40:36.426303Z",
     "shell.execute_reply.started": "2025-04-20T11:40:28.016325Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.5306 - loss: 0.6938 - val_accuracy: 0.5143 - val_loss: 0.6917\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6824 - loss: 0.6816 - val_accuracy: 0.5837 - val_loss: 0.6878\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8708 - loss: 0.6404 - val_accuracy: 0.5551 - val_loss: 0.7045\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8193 - loss: 0.4626 - val_accuracy: 0.5633 - val_loss: 0.7057\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9735 - loss: 0.2479 - val_accuracy: 0.6163 - val_loss: 0.8350\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.0987 - val_accuracy: 0.5265 - val_loss: 0.8430\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0468 - val_accuracy: 0.5551 - val_loss: 1.0968\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0209 - val_accuracy: 0.5429 - val_loss: 1.1233\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0102 - val_accuracy: 0.5510 - val_loss: 1.3155\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0074 - val_accuracy: 0.6082 - val_loss: 1.2105\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0164 - val_accuracy: 0.5633 - val_loss: 1.0847\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0056 - val_accuracy: 0.5429 - val_loss: 1.4842\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0038 - val_accuracy: 0.5347 - val_loss: 1.2990\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0048 - val_accuracy: 0.5347 - val_loss: 1.6304\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.5469 - val_loss: 1.3278\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.5551 - val_loss: 1.5083\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.5429 - val_loss: 1.3860\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.5469 - val_loss: 1.4958\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.0096 - val_accuracy: 0.5551 - val_loss: 1.6090\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0043 - val_accuracy: 0.5551 - val_loss: 1.5518\n"
     ]
    }
   ],
   "source": [
    "# Build the GRU model with the best hyperparameters\n",
    "best_gru_model = gru_tuner.hypermodel.build(best_gru_hps)\n",
    "\n",
    "# Train the GRU model with the best hyperparameters\n",
    "history_gru = best_gru_model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_pad, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:40:42.181356Z",
     "iopub.status.busy": "2025-04-20T11:40:42.180875Z",
     "iopub.status.idle": "2025-04-20T11:40:43.456347Z",
     "shell.execute_reply": "2025-04-20T11:40:43.455627Z",
     "shell.execute_reply.started": "2025-04-20T11:40:42.181331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "GRU Model Results:\n",
      "Accuracy: 0.5551020408163265\n",
      "Precision: 0.5407407407407407\n",
      "Recall: 0.6083333333333333\n",
      "F1 Score: 0.5725490196078431\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the GRU model\n",
    "y_pred_gru = (best_gru_model.predict(X_test_pad) > 0.5).astype('int32')\n",
    "\n",
    "# Metrics\n",
    "print(\"GRU Model Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gru))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_gru))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_gru))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_gru))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:44:11.080778Z",
     "iopub.status.busy": "2025-04-20T11:44:11.080515Z",
     "iopub.status.idle": "2025-04-20T11:44:11.086593Z",
     "shell.execute_reply": "2025-04-20T11:44:11.085842Z",
     "shell.execute_reply.started": "2025-04-20T11:44:11.080759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model-building function for LSTM with tunable hyperparameters\n",
    "def build_lstm_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tune the embedding output dimension\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=hp.Int('embedding_dim', min_value=64, max_value=256, step=64), \n",
    "                        input_length=max_length))\n",
    "    \n",
    "    # Tune LSTM units and add Bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(\n",
    "        units=hp.Int('lstm_units', min_value=64, max_value=256, step=64), \n",
    "        return_sequences=False)))\n",
    "    \n",
    "    # Tune dropout rate\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model with tunable learning rate\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:44:13.100544Z",
     "iopub.status.busy": "2025-04-20T11:44:13.099773Z",
     "iopub.status.idle": "2025-04-20T11:44:13.125296Z",
     "shell.execute_reply": "2025-04-20T11:44:13.124805Z",
     "shell.execute_reply.started": "2025-04-20T11:44:13.100509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the Hyperparameter tuner for LSTM\n",
    "tuner_lstm = kt.RandomSearch(\n",
    "    build_lstm_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of models to try\n",
    "    executions_per_trial=3,  # Number of models to run for each trial\n",
    "    directory='lstm_tuning',\n",
    "    project_name='lstm_hyperparam_tuning'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:44:33.185406Z",
     "iopub.status.busy": "2025-04-20T11:44:33.185134Z",
     "iopub.status.idle": "2025-04-20T11:46:27.513077Z",
     "shell.execute_reply": "2025-04-20T11:46:27.512517Z",
     "shell.execute_reply.started": "2025-04-20T11:44:33.185385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 23s]\n",
      "val_accuracy: 0.6122449040412903\n",
      "\n",
      "Best val_accuracy So Far: 0.6122449040412903\n",
      "Total elapsed time: 00h 01m 54s\n"
     ]
    }
   ],
   "source": [
    "# Perform the search using the training data\n",
    "tuner_lstm.search(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:48:38.773793Z",
     "iopub.status.busy": "2025-04-20T11:48:38.773063Z",
     "iopub.status.idle": "2025-04-20T11:48:38.777967Z",
     "shell.execute_reply": "2025-04-20T11:48:38.777246Z",
     "shell.execute_reply.started": "2025-04-20T11:48:38.773769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LSTM: {'embedding_dim': 128, 'lstm_units': 192, 'dropout_rate': 0.4, 'learning_rate': 0.0008145957107201968}\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps_lstm = tuner_lstm.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters for LSTM: {best_hps_lstm.values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:48:44.018826Z",
     "iopub.status.busy": "2025-04-20T11:48:44.018257Z",
     "iopub.status.idle": "2025-04-20T11:48:53.244551Z",
     "shell.execute_reply": "2025-04-20T11:48:53.243978Z",
     "shell.execute_reply.started": "2025-04-20T11:48:44.018801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.4918 - loss: 0.6944 - val_accuracy: 0.4898 - val_loss: 0.6926\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5666 - loss: 0.6801 - val_accuracy: 0.5755 - val_loss: 0.6769\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7900 - loss: 0.6202 - val_accuracy: 0.5878 - val_loss: 0.6922\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9113 - loss: 0.4196 - val_accuracy: 0.5755 - val_loss: 0.7303\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9720 - loss: 0.1393 - val_accuracy: 0.5592 - val_loss: 0.8320\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9792 - loss: 0.0914 - val_accuracy: 0.5878 - val_loss: 1.0357\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9973 - loss: 0.0263 - val_accuracy: 0.5673 - val_loss: 0.9497\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0163 - val_accuracy: 0.5265 - val_loss: 1.3942\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0111 - val_accuracy: 0.6163 - val_loss: 1.4329\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9966 - loss: 0.0173 - val_accuracy: 0.6000 - val_loss: 0.9647\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0098 - val_accuracy: 0.5306 - val_loss: 1.2732\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0113 - val_accuracy: 0.5714 - val_loss: 1.2696\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0040 - val_accuracy: 0.5837 - val_loss: 1.3747\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0031 - val_accuracy: 0.5714 - val_loss: 1.4651\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.5673 - val_loss: 1.3649\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.5714 - val_loss: 1.5682\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9977 - loss: 0.0052 - val_accuracy: 0.5714 - val_loss: 1.5136\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9984 - loss: 0.0041 - val_accuracy: 0.5673 - val_loss: 1.4593\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0016 - val_accuracy: 0.5673 - val_loss: 1.6258\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0111 - val_accuracy: 0.5673 - val_loss: 1.4318\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the best hyperparameters\n",
    "best_lstm_model = tuner_lstm.hypermodel.build(best_hps_lstm)\n",
    "\n",
    "# Train the best LSTM model\n",
    "history_lstm = best_lstm_model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_pad, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:48:56.897805Z",
     "iopub.status.busy": "2025-04-20T11:48:56.896965Z",
     "iopub.status.idle": "2025-04-20T11:48:58.261987Z",
     "shell.execute_reply": "2025-04-20T11:48:58.261317Z",
     "shell.execute_reply.started": "2025-04-20T11:48:56.897771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step\n",
      "Best LSTM Model Results:\n",
      "Accuracy: 0.5673469387755102\n",
      "Precision: 0.5460526315789473\n",
      "Recall: 0.6916666666666667\n",
      "F1 Score: 0.6102941176470589\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_best_lstm = (best_lstm_model.predict(X_test_pad) > 0.5).astype('int32')\n",
    "\n",
    "# Metrics\n",
    "print(\"Best LSTM Model Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best_lstm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_best_lstm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_best_lstm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_best_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BiLSTM Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:50:33.616264Z",
     "iopub.status.busy": "2025-04-20T11:50:33.615706Z",
     "iopub.status.idle": "2025-04-20T11:50:33.622213Z",
     "shell.execute_reply": "2025-04-20T11:50:33.621416Z",
     "shell.execute_reply.started": "2025-04-20T11:50:33.616239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model-building function for BiLSTM with tunable hyperparameters\n",
    "def build_bilstm_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tune the embedding output dimension\n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=hp.Int('embedding_dim', min_value=64, max_value=256, step=64), \n",
    "                        input_length=max_length))\n",
    "    \n",
    "    # Tune LSTM units and add Bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(\n",
    "        units=hp.Int('lstm_units', min_value=64, max_value=256, step=64), \n",
    "        return_sequences=False)))\n",
    "    \n",
    "    # Tune dropout rate\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model with tunable learning rate\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:52:03.719647Z",
     "iopub.status.busy": "2025-04-20T11:52:03.718925Z",
     "iopub.status.idle": "2025-04-20T11:53:56.694353Z",
     "shell.execute_reply": "2025-04-20T11:53:56.693739Z",
     "shell.execute_reply.started": "2025-04-20T11:52:03.719624Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 23s]\n",
      "val_accuracy: 0.6108843485514323\n",
      "\n",
      "Best val_accuracy So Far: 0.6299319863319397\n",
      "Total elapsed time: 00h 01m 53s\n"
     ]
    }
   ],
   "source": [
    "# Set up the Hyperparameter tuner for BiLSTM\n",
    "tuner_bilstm = kt.RandomSearch(\n",
    "    build_bilstm_model,  # Our model-building function\n",
    "    objective='val_accuracy',  # Goal: maximize validation accuracy\n",
    "    max_trials=5,  # Try 5 different sets of hyperparameters\n",
    "    executions_per_trial=3,  # Run each set 3 times and average\n",
    "    directory='bilstm_tuning',  # Folder to save results\n",
    "    project_name='bilstm_hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Start the hyperparameter search\n",
    "tuner_bilstm.search(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:54:44.448581Z",
     "iopub.status.busy": "2025-04-20T11:54:44.447963Z",
     "iopub.status.idle": "2025-04-20T11:54:44.452438Z",
     "shell.execute_reply": "2025-04-20T11:54:44.451651Z",
     "shell.execute_reply.started": "2025-04-20T11:54:44.448557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7dd438be0bd0>\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters from the tuner\n",
    "best_bilstm_hps = tuner_bilstm.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_bilstm_hps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:54:50.828946Z",
     "iopub.status.busy": "2025-04-20T11:54:50.828307Z",
     "iopub.status.idle": "2025-04-20T11:54:59.579700Z",
     "shell.execute_reply": "2025-04-20T11:54:59.579168Z",
     "shell.execute_reply.started": "2025-04-20T11:54:50.828921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5223 - loss: 0.6934 - val_accuracy: 0.5306 - val_loss: 0.6893\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6830 - loss: 0.6478 - val_accuracy: 0.5796 - val_loss: 0.6702\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8763 - loss: 0.3935 - val_accuracy: 0.5714 - val_loss: 0.7145\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9506 - loss: 0.2202 - val_accuracy: 0.5388 - val_loss: 0.9044\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9876 - loss: 0.0822 - val_accuracy: 0.5796 - val_loss: 0.9942\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9928 - loss: 0.0373 - val_accuracy: 0.5633 - val_loss: 1.2122\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0241 - val_accuracy: 0.5592 - val_loss: 1.1760\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0204 - val_accuracy: 0.5714 - val_loss: 1.2058\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9933 - loss: 0.0254 - val_accuracy: 0.5796 - val_loss: 1.2548\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9989 - loss: 0.0105 - val_accuracy: 0.5918 - val_loss: 1.3792\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0102 - val_accuracy: 0.5714 - val_loss: 1.4915\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0078 - val_accuracy: 0.5878 - val_loss: 1.5279\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9993 - loss: 0.0047 - val_accuracy: 0.5837 - val_loss: 1.5930\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9973 - loss: 0.0058 - val_accuracy: 0.5878 - val_loss: 1.6434\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9968 - loss: 0.0063 - val_accuracy: 0.5918 - val_loss: 1.6620\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0059 - val_accuracy: 0.5878 - val_loss: 1.7227\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.5918 - val_loss: 1.7433\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0044 - val_accuracy: 0.5918 - val_loss: 1.8039\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.5918 - val_loss: 1.8395\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.5959 - val_loss: 1.8878\n"
     ]
    }
   ],
   "source": [
    "# Build the best BiLSTM model using the found hyperparameters\n",
    "best_bilstm_model = tuner_bilstm.hypermodel.build(best_bilstm_hps)\n",
    "\n",
    "# Train the best model\n",
    "history_bilstm = best_bilstm_model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_pad, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T11:55:26.635883Z",
     "iopub.status.busy": "2025-04-20T11:55:26.635167Z",
     "iopub.status.idle": "2025-04-20T11:55:26.741559Z",
     "shell.execute_reply": "2025-04-20T11:55:26.740943Z",
     "shell.execute_reply.started": "2025-04-20T11:55:26.635851Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Best BiLSTM Model Results:\n",
      "Accuracy: 0.5959183673469388\n",
      "Precision: 0.5695364238410596\n",
      "Recall: 0.7166666666666667\n",
      "F1 Score: 0.6346863468634687\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model\n",
    "y_pred_bilstm = (best_bilstm_model.predict(X_test_pad) > 0.5).astype('int32')\n",
    "\n",
    "# Metrics\n",
    "print(\"Best BiLSTM Model Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bilstm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_bilstm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_bilstm))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_bilstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mBERT Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:39:43.919247Z",
     "iopub.status.busy": "2025-04-20T14:39:43.918964Z",
     "iopub.status.idle": "2025-04-20T14:39:43.952872Z",
     "shell.execute_reply": "2025-04-20T14:39:43.952177Z",
     "shell.execute_reply.started": "2025-04-20T14:39:43.919228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # helps catch CUDA errors early\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:05:13.480515Z",
     "iopub.status.busy": "2025-04-20T14:05:13.479933Z",
     "iopub.status.idle": "2025-04-20T14:05:13.528999Z",
     "shell.execute_reply": "2025-04-20T14:05:13.528301Z",
     "shell.execute_reply.started": "2025-04-20T14:05:13.480491Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    499\n",
      "1    480\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('/kaggle/input/urduuusentiment/urdu-sentiment-corpus-v1.tsv', sep='\\t')\n",
    "\n",
    "# Remove rows with labels other than Positive (P) and Negative (N)\n",
    "df = df[df['Class'].isin(['P', 'N'])].reset_index(drop=True)\n",
    "\n",
    "# Encode labels: P -> 1 (positive), N -> 0 (negative)\n",
    "df['label'] = df['Class'].map({'P': 1, 'N': 0})\n",
    "\n",
    "print(df['label'].value_counts())  # Check distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:05:24.782599Z",
     "iopub.status.busy": "2025-04-20T14:05:24.782331Z",
     "iopub.status.idle": "2025-04-20T14:05:24.788979Z",
     "shell.execute_reply": "2025-04-20T14:05:24.788265Z",
     "shell.execute_reply.started": "2025-04-20T14:05:24.782574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['Tweet'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=df['label']  # Maintain class balance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:05:30.122148Z",
     "iopub.status.busy": "2025-04-20T14:05:30.121875Z",
     "iopub.status.idle": "2025-04-20T14:05:30.693033Z",
     "shell.execute_reply": "2025-04-20T14:05:30.692476Z",
     "shell.execute_reply.started": "2025-04-20T14:05:30.122128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenizing inside Dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:05:35.490325Z",
     "iopub.status.busy": "2025-04-20T14:05:35.490047Z",
     "iopub.status.idle": "2025-04-20T14:05:35.496499Z",
     "shell.execute_reply": "2025-04-20T14:05:35.495755Z",
     "shell.execute_reply.started": "2025-04-20T14:05:35.490304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:05:39.357816Z",
     "iopub.status.busy": "2025-04-20T14:05:39.357524Z",
     "iopub.status.idle": "2025-04-20T14:05:42.874973Z",
     "shell.execute_reply": "2025-04-20T14:05:42.874266Z",
     "shell.execute_reply.started": "2025-04-20T14:05:39.357797Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7202c9088efc49b989d997821a496613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:05:47.028141Z",
     "iopub.status.busy": "2025-04-20T14:05:47.027870Z",
     "iopub.status.idle": "2025-04-20T14:05:47.032544Z",
     "shell.execute_reply": "2025-04-20T14:05:47.031865Z",
     "shell.execute_reply.started": "2025-04-20T14:05:47.028123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:08:21.424028Z",
     "iopub.status.busy": "2025-04-20T14:08:21.423363Z",
     "iopub.status.idle": "2025-04-20T14:08:21.454204Z",
     "shell.execute_reply": "2025-04-20T14:08:21.453587Z",
     "shell.execute_reply.started": "2025-04-20T14:08:21.423997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,      # Hyperparameter you can tune\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,      # You can increase for better results\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:08:24.336988Z",
     "iopub.status.busy": "2025-04-20T14:08:24.336407Z",
     "iopub.status.idle": "2025-04-20T14:12:32.899567Z",
     "shell.execute_reply": "2025-04-20T14:12:32.899000Z",
     "shell.execute_reply.started": "2025-04-20T14:08:24.336965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [920/920 04:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=920, training_loss=0.08613184897795967, metrics={'train_runtime': 248.0593, 'train_samples_per_second': 59.179, 'train_steps_per_second': 3.709, 'total_flos': 965617573171200.0, 'train_loss': 0.08613184897795967, 'epoch': 20.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T14:12:41.525763Z",
     "iopub.status.busy": "2025-04-20T14:12:41.525441Z",
     "iopub.status.idle": "2025-04-20T14:12:42.660200Z",
     "shell.execute_reply": "2025-04-20T14:12:42.659645Z",
     "shell.execute_reply.started": "2025-04-20T14:12:41.525742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.1721458435058594,\n",
       " 'eval_accuracy': 0.6653061224489796,\n",
       " 'eval_precision': 0.6610169491525424,\n",
       " 'eval_recall': 0.65,\n",
       " 'eval_f1': 0.6554621848739496,\n",
       " 'eval_runtime': 1.1278,\n",
       " 'eval_samples_per_second': 217.229,\n",
       " 'eval_steps_per_second': 14.186,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XLM-RoBERTa Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:10:43.172045Z",
     "iopub.status.busy": "2025-04-20T15:10:43.171759Z",
     "iopub.status.idle": "2025-04-20T15:10:43.176037Z",
     "shell.execute_reply": "2025-04-20T15:10:43.175356Z",
     "shell.execute_reply.started": "2025-04-20T15:10:43.172024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import XLMRobertaTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:02:08.308252Z",
     "iopub.status.busy": "2025-04-20T15:02:08.307550Z",
     "iopub.status.idle": "2025-04-20T15:02:08.394951Z",
     "shell.execute_reply": "2025-04-20T15:02:08.394417Z",
     "shell.execute_reply.started": "2025-04-20T15:02:08.308227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('/kaggle/input/urduuusentiment/urdu-sentiment-corpus-v1.tsv', sep='\\t')\n",
    "df = df[['Tweet', 'Class']].dropna()\n",
    "df = df[df['Class'].isin(['P', 'N'])]  # Only keep Positive/Negative\n",
    "\n",
    "# Encode labels\n",
    "label_mapping = {'P': 1, 'N': 0}\n",
    "df['label'] = df['Class'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:02:19.158136Z",
     "iopub.status.busy": "2025-04-20T15:02:19.157439Z",
     "iopub.status.idle": "2025-04-20T15:02:19.172658Z",
     "shell.execute_reply": "2025-04-20T15:02:19.171810Z",
     "shell.execute_reply.started": "2025-04-20T15:02:19.158102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['Tweet'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=df['label']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:02:32.356734Z",
     "iopub.status.busy": "2025-04-20T15:02:32.356271Z",
     "iopub.status.idle": "2025-04-20T15:02:35.731376Z",
     "shell.execute_reply": "2025-04-20T15:02:35.730667Z",
     "shell.execute_reply.started": "2025-04-20T15:02:32.356710Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e263c98a6e964a54af94f0080de66ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06798c99fb2844d5aedb3ea48d79ffd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f565f69a0434f5282dc3cceb1831b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b468f4da0b24b208d212cbbbc6bc06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:03:00.695078Z",
     "iopub.status.busy": "2025-04-20T15:03:00.694352Z",
     "iopub.status.idle": "2025-04-20T15:03:00.824324Z",
     "shell.execute_reply": "2025-04-20T15:03:00.823861Z",
     "shell.execute_reply.started": "2025-04-20T15:03:00.695043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:03:13.057327Z",
     "iopub.status.busy": "2025-04-20T15:03:13.056805Z",
     "iopub.status.idle": "2025-04-20T15:03:13.062075Z",
     "shell.execute_reply": "2025-04-20T15:03:13.061279Z",
     "shell.execute_reply.started": "2025-04-20T15:03:13.057308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "class UrduSentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = UrduSentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = UrduSentimentDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:05:54.090397Z",
     "iopub.status.busy": "2025-04-20T15:05:54.089886Z",
     "iopub.status.idle": "2025-04-20T15:05:54.094899Z",
     "shell.execute_reply": "2025-04-20T15:05:54.094228Z",
     "shell.execute_reply.started": "2025-04-20T15:05:54.090374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:06:11.047456Z",
     "iopub.status.busy": "2025-04-20T15:06:11.047195Z",
     "iopub.status.idle": "2025-04-20T15:06:11.079383Z",
     "shell.execute_reply": "2025-04-20T15:06:11.078830Z",
     "shell.execute_reply.started": "2025-04-20T15:06:11.047438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,         \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,     \n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,                   # <-- Log after every 10 steps\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:06:13.308340Z",
     "iopub.status.busy": "2025-04-20T15:06:13.307549Z",
     "iopub.status.idle": "2025-04-20T15:06:13.536575Z",
     "shell.execute_reply": "2025-04-20T15:06:13.535957Z",
     "shell.execute_reply.started": "2025-04-20T15:06:13.308318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:06:17.022615Z",
     "iopub.status.busy": "2025-04-20T15:06:17.021986Z",
     "iopub.status.idle": "2025-04-20T15:09:55.487667Z",
     "shell.execute_reply": "2025-04-20T15:09:55.486954Z",
     "shell.execute_reply.started": "2025-04-20T15:06:17.022587Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 03:37, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.697200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.694700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.691700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.674100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.666200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.596300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.565900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.500400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.478300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.351800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.355400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.287100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.417300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.339500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.171200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.148200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.139100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.100200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.097700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.075300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.077100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.040500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.050500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=460, training_loss=0.2627279550484989, metrics={'train_runtime': 217.4972, 'train_samples_per_second': 67.495, 'train_steps_per_second': 2.115, 'total_flos': 460177124714400.0, 'train_loss': 0.2627279550484989, 'epoch': 20.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:10:47.765605Z",
     "iopub.status.busy": "2025-04-20T15:10:47.765345Z",
     "iopub.status.idle": "2025-04-20T15:10:48.846673Z",
     "shell.execute_reply": "2025-04-20T15:10:48.846075Z",
     "shell.execute_reply.started": "2025-04-20T15:10:47.765575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6473727226257324, 'eval_accuracy': 0.710204081632653, 'eval_precision': 0.7024793388429752, 'eval_recall': 0.7083333333333334, 'eval_f1': 0.7053941908713693, 'eval_runtime': 1.0752, 'eval_samples_per_second': 227.864, 'eval_steps_per_second': 7.44, 'epoch': 20.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2) Sentiment Analysis using word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:25:33.971639Z",
     "iopub.status.busy": "2025-04-20T15:25:33.971109Z",
     "iopub.status.idle": "2025-04-20T15:25:34.013233Z",
     "shell.execute_reply": "2025-04-20T15:25:34.012585Z",
     "shell.execute_reply.started": "2025-04-20T15:25:33.971601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet  \\\n",
      "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...   \n",
      "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...   \n",
      "2                           ٹویٹر کا خیال کیسے آیا ؟   \n",
      "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...   \n",
      "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ   \n",
      "\n",
      "                                         Tweet_clean  \n",
      "0  میں نے ایٹم بم بنایا ھے او بھائی ایٹم بمب کوٹ ...  \n",
      "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...  \n",
      "2                             ٹویٹر کا خیال کیسے آیا  \n",
      "3  سرچ انجن گوگل کے نائب صدر نے فضا میں   فٹ کی ب...  \n",
      "4      ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار أ  \n"
     ]
    }
   ],
   "source": [
    "# Preprocessing Urdu Tweets\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('/kaggle/input/urduuusentiment/urdu-sentiment-corpus-v1.tsv', sep='\\t')\n",
    "\n",
    "# Basic text cleaning function\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)       # Remove numbers\n",
    "    text = text.strip()                   # Remove leading/trailing whitespace\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df['Tweet_clean'] = df['Tweet'].apply(clean_text)\n",
    "\n",
    "# View cleaned tweets\n",
    "print(df[['Tweet', 'Tweet_clean']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:26:33.531550Z",
     "iopub.status.busy": "2025-04-20T15:26:33.531281Z",
     "iopub.status.idle": "2025-04-20T15:26:33.539262Z",
     "shell.execute_reply": "2025-04-20T15:26:33.538555Z",
     "shell.execute_reply.started": "2025-04-20T15:26:33.531531Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['میں', 'نے', 'ایٹم', 'بم', 'بنایا', 'ھے', 'او', 'بھائی', 'ایٹم', 'بمب', 'کوٹ', 'لکھپت', 'والی', 'اتفاق', 'فیکٹری', 'میں', 'نہیں', 'بنتاایٹم', 'بم', 'کہوٹہ', 'کی', 'ایٹمی'], ['چندے', 'سے', 'انقلاب', 'اور', 'عمران', 'خان', 'وزیر', 'اعظم', 'نہیں', 'بن', 'سکتے'], ['ٹویٹر', 'کا', 'خیال', 'کیسے', 'آیا'], ['سرچ', 'انجن', 'گوگل', 'کے', 'نائب', 'صدر', 'نے', 'فضا', 'میں', 'فٹ', 'کی', 'بلندی', 'پر', 'چھلانگ', 'لگا', 'کر', 'عالمی', 'ریکارڈ', 'قائم', 'کرلیا', 'چھلانگ', 'کی'], ['ابھی', 'تک', 'اسکی', 'لہریں', 'کبھی', 'کبھی', 'آ', 'جاتی', 'ہیں', 'یار', 'أ']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization of Tweets\n",
    "\n",
    "# Simple Urdu word tokenizer (split by space for now)\n",
    "df['tokens'] = df['Tweet_clean'].apply(lambda x: x.split())\n",
    "\n",
    "# Final tokenized sentences\n",
    "sentences = df['tokens'].tolist()\n",
    "\n",
    "# Example\n",
    "print(sentences[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:27:04.797579Z",
     "iopub.status.busy": "2025-04-20T15:27:04.796929Z",
     "iopub.status.idle": "2025-04-20T15:28:18.664935Z",
     "shell.execute_reply": "2025-04-20T15:28:18.664220Z",
     "shell.execute_reply.started": "2025-04-20T15:27:04.797560Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.51141837e-01  5.41772008e-01  2.15594098e-01  2.17439607e-01\n",
      "  2.77114974e-04 -5.33531427e-01  3.57072443e-01  1.21154511e+00\n",
      "  2.52480991e-02 -2.48894647e-01  2.55344599e-01 -3.82782698e-01\n",
      " -3.76747400e-02  1.21510193e-01 -4.42663819e-01 -3.47939938e-01\n",
      "  3.30831140e-01 -2.58046445e-02  2.54350305e-01 -2.24813491e-01\n",
      " -3.45094889e-01 -1.91343725e-01  2.69015878e-01  9.55679864e-02\n",
      "  4.15248722e-01 -3.27576734e-02 -6.13531768e-01  3.21235619e-02\n",
      " -1.84451342e-01 -5.04071534e-01  1.60372481e-01 -3.59600812e-01\n",
      "  1.76599786e-01 -4.31130454e-02 -8.64950418e-02  1.81792781e-01\n",
      "  2.13999197e-01 -6.41518533e-01 -8.83256942e-02 -1.70747653e-01\n",
      " -1.06607832e-01 -2.13540252e-02  6.95098937e-02 -2.98653066e-01\n",
      "  3.22362304e-01  4.45875883e-01  3.84498052e-02  2.55491197e-01\n",
      " -1.28287047e-01  2.93594718e-01  1.32580414e-01 -6.25952659e-03\n",
      " -4.24361706e-01  1.82349056e-01 -6.96496218e-02  4.49375123e-01\n",
      "  1.54175714e-01 -5.50237522e-02  2.41108850e-01 -4.93541807e-02\n",
      " -1.31593496e-01 -5.62646203e-02  1.51234190e-03  1.93932071e-01\n",
      "  1.54992957e-02  1.64989099e-01 -7.19195679e-02  1.24406718e-01\n",
      " -4.47545350e-01 -6.79663345e-02 -1.62047837e-02  5.37048340e-01\n",
      "  4.93795216e-01 -3.72700036e-01  2.03478932e-01  1.60841152e-01\n",
      " -3.91907185e-01  1.07012175e-01 -2.15015545e-01  4.48180795e-01\n",
      " -2.13786006e-01 -3.63067836e-01 -7.97499940e-02  9.44527209e-01\n",
      "  1.30236149e-01  1.09581500e-01 -1.33516014e-01 -3.53346467e-02\n",
      "  4.73931700e-01  3.91726017e-01  3.62804323e-01 -3.08028668e-01\n",
      "  2.10037097e-01  1.10420110e-02  5.17669976e-01  4.70278352e-01\n",
      "  4.19839591e-01 -2.44942620e-01 -1.76358759e-01  3.14959288e-01\n",
      "  7.83123262e-03 -5.26575893e-02  5.06874681e-01  1.46207869e-01\n",
      " -1.41783664e-02 -4.45116371e-01 -2.17733867e-02  1.29940867e-01\n",
      " -5.07860243e-01  4.15974371e-02 -4.44369465e-01 -3.29384804e-01\n",
      "  2.79654429e-04  3.16763878e-01  2.45682001e-01  3.10846657e-01\n",
      " -8.31773654e-02 -9.63726789e-02  4.98021573e-01 -6.70279503e-01\n",
      "  3.14322740e-01  4.29951429e-01  4.07304198e-01 -2.76884995e-02\n",
      " -3.08286846e-01  4.66751724e-01 -9.50960219e-02 -4.68273848e-01\n",
      " -4.37309928e-02  3.86813015e-01  2.25600630e-01  6.20857656e-01\n",
      "  3.34029309e-02 -6.19570434e-01  2.38961965e-01  3.54287505e-01\n",
      " -8.83366764e-02 -2.68266648e-01 -6.54647470e-01 -5.35941005e-01\n",
      "  2.53511608e-01 -4.44402754e-01 -2.22599596e-01  4.24067199e-01\n",
      "  2.91051298e-01 -3.14914137e-01 -6.58500791e-01 -2.29863301e-01\n",
      "  3.73723567e-01 -3.13886940e-01  7.27533326e-02 -8.75718296e-01\n",
      " -3.90369505e-01 -2.48902962e-01  5.86110130e-02  3.58947098e-01\n",
      " -4.69595879e-01 -2.69743800e-01 -6.96024373e-02  5.86642742e-01\n",
      "  1.43495798e-01  2.78846502e-01 -4.04039145e-01  5.26431859e-01\n",
      " -1.36396721e-01  2.46820480e-01 -5.72796576e-02  3.53396349e-02\n",
      "  8.42218325e-02  7.06255198e-01 -2.31317237e-01  1.24752916e-01\n",
      "  2.44326606e-01  1.54841378e-01 -1.41423389e-01  1.08303837e-01\n",
      "  6.40717596e-02 -2.80104667e-01  1.01149209e-01 -1.49891600e-01\n",
      " -3.78457189e-01  1.10499933e-01 -4.13832277e-01 -3.25344175e-01\n",
      " -3.20688218e-01  2.23214123e-02  5.22303700e-01  4.98556495e-01\n",
      "  2.77437061e-01 -5.87918937e-01  1.46664634e-01 -3.70950252e-02\n",
      " -4.67685312e-01  5.76727353e-02  1.80535197e-01 -4.24453467e-01\n",
      "  8.51545334e-02 -4.21057463e-01  1.10708721e-01  4.68054116e-02\n",
      " -3.84866625e-01  3.04487973e-01 -1.11565143e-01 -2.76674360e-01\n",
      "  9.57250521e-02 -2.29701862e-01 -1.23649538e-01  3.21317196e-01\n",
      " -3.18710431e-02 -1.10198237e-01 -1.24214411e-01 -5.34601212e-01\n",
      " -2.56303161e-01 -2.23093241e-01  4.26044613e-01 -5.82545102e-01\n",
      " -2.54300982e-01 -7.85294354e-01 -6.38511181e-01 -5.12522876e-01\n",
      "  3.95495862e-01 -9.84412897e-03 -2.30017945e-01 -3.57206315e-01\n",
      " -3.81743908e-01 -3.35414559e-01 -4.84361313e-02 -1.93575546e-01\n",
      " -1.82089329e-01  1.57204255e-01  3.25666666e-01 -2.16097772e-01\n",
      " -2.31857494e-01  2.97167391e-01 -3.67394805e-01  3.39496881e-01\n",
      " -6.12759590e-02  4.03717846e-01  6.41300008e-02 -6.60870671e-01\n",
      "  4.39315140e-01 -3.28338206e-01 -2.85633773e-01 -9.75517258e-02\n",
      " -3.14631164e-02 -5.55671036e-01  6.87587354e-03 -2.14819778e-02\n",
      "  1.13588698e-01  3.67981434e-01  8.00040588e-02  1.38125211e-01\n",
      "  3.25866520e-01  6.71966746e-02 -5.43702543e-01 -2.35617027e-01\n",
      "  6.86711431e-01  2.03308716e-01 -6.31725609e-01 -4.34152275e-01\n",
      "  2.33452663e-01  1.65056437e-01  1.27563089e-01 -8.21620166e-01\n",
      " -6.66276157e-01  1.55938312e-01  1.85592622e-01  2.71680653e-01\n",
      " -4.41759646e-01  1.42644033e-01 -3.34819734e-01  5.68607971e-02\n",
      "  3.65457721e-02 -1.01104185e-01  4.61364865e-01  1.30390599e-01\n",
      "  4.24469382e-01  1.83978379e-01 -5.27309179e-01 -2.09827945e-02\n",
      "  1.82772905e-01 -2.94736493e-03 -8.12754259e-02  1.70065045e-01\n",
      " -1.03533315e-02  1.26178756e-01 -6.74692273e-01  3.27892423e-01\n",
      "  4.14458215e-02  4.93966728e-01  1.38977915e-01  5.78710377e-01\n",
      "  4.24873531e-01  4.78279814e-02  4.71460283e-01  6.00775957e-01\n",
      "  1.19820178e-01 -1.91250518e-01  3.77969623e-01 -1.65413648e-01]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train Word2Vec\n",
    "w2v_model = Word2Vec(sentences, vector_size=300, window=5, min_count=1, workers=4, epochs=30)\n",
    "\n",
    "# Save the model\n",
    "w2v_model.save(\"urdu_word2vec.model\")\n",
    "\n",
    "# Example: Get vector for a word\n",
    "print(w2v_model.wv['خان'])  # example Urdu word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T15:32:03.653703Z",
     "iopub.status.busy": "2025-04-20T15:32:03.653160Z",
     "iopub.status.idle": "2025-04-20T15:32:11.368862Z",
     "shell.execute_reply": "2025-04-20T15:32:11.368097Z",
     "shell.execute_reply.started": "2025-04-20T15:32:03.653684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7710025  -0.00761759 -0.7132654  -0.10891396 -0.82844436 -0.0724377\n",
      "  0.33335805  1.0826792  -0.04404404  0.21507658 -0.40715948 -0.08789742\n",
      "  0.10447229  0.13141426  0.09518748 -0.53553563 -0.40565902 -0.36894134\n",
      " -0.27015433 -0.24066754  0.12243818  0.6302248  -0.0422199   0.6447443\n",
      "  0.51001173  0.27972725  0.05001359  0.3714595  -0.14511628 -0.09012616\n",
      "  0.2187682  -0.38321766 -0.04787967  0.35637277  0.17888358 -0.00199761\n",
      "  0.25056022 -0.5560907   0.5798305  -0.36930317  0.42911673  0.05930861\n",
      "  0.11312318 -0.24293756  0.16484189  0.14753099  0.2129542  -0.6124335\n",
      "  0.10325637  0.73409545  0.11598943  0.08297802 -0.12618081  0.7337373\n",
      "  0.75490665  0.6171598   0.34810203  0.02325491  0.5853562   0.44657072\n",
      " -0.42837605 -0.42833647 -0.23218744  0.3663659   0.7757973   0.04900873\n",
      " -0.38509688  0.40972418 -0.4584365   0.69155353 -0.38657925  0.10676061\n",
      "  0.11707739 -0.1094055  -0.2292334   0.3644038  -0.16262412  0.08662166\n",
      " -0.10579     0.39030442  0.20970008 -0.5205685  -0.12878169  0.4291926\n",
      " -0.62024456 -0.23107474 -0.37626845  0.14841507  0.27252525 -0.40184966\n",
      "  0.5395975  -0.26501375 -0.48542494  0.6646903   0.6807322   0.31867662\n",
      "  0.20067981 -0.05272624  0.05324678 -0.29466882  0.36909184  0.10132061\n",
      " -0.04042071 -0.03054923  0.41383043 -0.10457862 -0.02082327 -0.17654225\n",
      "  0.02980067 -0.21578881  0.08988988  0.48280764 -0.84413046  0.10822273\n",
      "  0.23957501  0.8699771   0.2554249  -0.33950302  0.44017357 -0.14118935\n",
      "  0.36641592  0.5416714   0.77820957  0.5511642   0.15104474  0.44024137\n",
      " -0.58303326 -0.49200383  0.12487571 -0.06154333 -0.6828011  -0.7669385\n",
      " -0.6395613  -0.60532415  0.15581931 -0.01759087  0.75353384  0.26478666\n",
      " -0.48610562  0.02946992 -0.4594931  -0.69245434 -0.02118255 -0.25815096\n",
      "  0.4186406   0.32549763 -0.08344    -0.54037005  0.30694738  0.27812585\n",
      "  0.36318928 -0.25699776 -0.38042575  0.25199968 -0.23094511  0.17871043\n",
      " -0.82256836 -0.26448312 -0.04987106 -0.03785228  0.28261283  0.2921594\n",
      " -0.5698991  -0.30230087 -0.4607739   0.5380801   0.04594536 -0.47373697\n",
      " -0.293511    0.48069617 -0.05721426 -0.08156843  0.33603302  0.05031665\n",
      "  0.49556366 -0.14706023  0.05426139  0.3205659  -0.29779455 -0.03969106\n",
      "  0.27023974 -0.4075589   0.47370318  0.7188223  -0.02768525  0.14027108\n",
      "  0.75292194 -0.17775695  0.10063357 -0.52614385 -0.4209497  -0.15256043\n",
      " -0.15686207 -0.7268043   0.5384532  -0.43797356  0.09942044 -0.13347307\n",
      "  0.41802058  0.24468386 -0.17463224 -0.44988623  0.05888765 -0.14697225\n",
      "  0.60248333  0.16890433 -0.34101748 -0.14666864 -0.61163366 -0.04944355\n",
      " -0.01212526 -0.40506458  0.03456388 -0.02705506  0.09717797 -0.7273127\n",
      " -0.2706603  -0.23942122 -0.33993965 -0.19031999 -0.93424976 -0.48144707\n",
      " -0.08666705 -0.29150683 -0.504986   -0.33117595 -0.27127904  0.16576588\n",
      "  0.08242542  0.22393428 -0.63127625 -0.33428636 -0.53911394  0.01046007\n",
      "  0.02215182 -0.08423071  0.5546025   0.23205377 -0.01718378 -0.73970425\n",
      " -0.2867642  -0.33300552  0.12304992  0.52190316  0.3318346  -0.64303774\n",
      "  0.883121   -0.6497798  -0.4601789   0.22457683 -0.06797102 -0.13738267\n",
      "  0.28540558  0.42060667 -0.91426086  0.501759   -0.497537    0.5970479\n",
      " -0.31854507 -0.24016239 -0.08569063 -0.5142664  -0.09724067  0.6832163\n",
      " -0.305638   -0.01434068 -0.10830964 -0.48491588 -0.48592642  0.778659\n",
      " -0.10166802  0.03830227 -0.123749   -0.3353412  -0.9266904   0.1547507\n",
      "  0.4419501   0.13702129 -0.9545683  -0.32428926 -0.19053291  0.3367388\n",
      "  0.43979144  0.06038124 -0.2289283   0.13625596  0.17346422  0.29131702\n",
      " -0.2630747   0.9380194   0.16923733 -0.0404557   0.00260109 -0.29132608\n",
      "  0.72027427 -0.3770735   0.5042067  -0.13006233 -0.1442077   0.32817724]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "# Train FastText\n",
    "ft_model = FastText(sentences, vector_size=300, window=5, min_count=1, workers=4, epochs=30)\n",
    "\n",
    "# Save the model\n",
    "ft_model.save(\"urdu_fasttext.model\")\n",
    "\n",
    "# Example\n",
    "print(ft_model.wv['خان'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T17:26:36.464705Z",
     "iopub.status.busy": "2025-04-20T17:26:36.464319Z",
     "iopub.status.idle": "2025-04-20T17:27:03.424955Z",
     "shell.execute_reply": "2025-04-20T17:27:03.424200Z",
     "shell.execute_reply.started": "2025-04-20T17:26:36.464671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.59159    1.1582     0.5159    -0.089872  -0.30491   -0.32017\n",
      " -0.24737   -0.23799    0.30642    0.27633    0.72432   -0.3281\n",
      " -0.59546    0.6052    -0.11869    0.83671    0.17238   -0.13105\n",
      "  0.44077    0.70813   -0.22314   -0.55746   -0.0037007  0.017325\n",
      " -0.072511   1.3471    -0.052981   0.0084129  0.56635    0.070343\n",
      " -0.46641    0.1831    -0.31445   -0.73833    0.39099   -0.92103\n",
      "  0.43325   -0.69386    0.14133    0.79592    0.11744    0.24983\n",
      "  0.11663   -0.25647    0.422     -0.90908   -0.49173    0.23067\n",
      "  0.44652    0.12588    0.28967    0.26124    0.26236   -0.13052\n",
      " -0.30259    0.25015   -0.64525   -0.092605  -0.89275   -0.58147\n",
      " -0.020689   0.019705  -0.28225   -0.88845   -0.48147    0.30782\n",
      " -0.14298   -1.0383    -0.18129    0.61952   -0.48386    1.1028\n",
      "  0.25364    0.30245    0.11214   -0.7666     0.018146  -0.068516\n",
      "  0.14089   -0.42505   -0.62971   -0.84632    0.21139   -0.35575\n",
      "  0.39461    0.14247   -0.064626  -0.56695   -0.16673    0.018844\n",
      " -0.065712   0.6176     0.75857   -0.60924   -0.67222    0.066737\n",
      "  0.0026248  0.20449   -0.76835    0.13479  ]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained GloVe vectors (make sure to use the correct path)\n",
    "glove_file = '/kaggle/input/glove-6b-100-d/glove.6B.100d.txt'  # Adjust the path accordingly\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)\n",
    "\n",
    "# Example: Retrieve vector for the word 'خان' (a common Urdu word)\n",
    "word_vector = glove_model['خان']\n",
    "print(word_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:07:54.363064Z",
     "iopub.status.busy": "2025-04-20T18:07:54.362290Z",
     "iopub.status.idle": "2025-04-20T18:07:54.367148Z",
     "shell.execute_reply": "2025-04-20T18:07:54.366421Z",
     "shell.execute_reply.started": "2025-04-20T18:07:54.363032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Target labels\n",
    "y = df['label']  # Make sure your label column is named 'label'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:08:04.615111Z",
     "iopub.status.busy": "2025-04-20T18:08:04.614505Z",
     "iopub.status.idle": "2025-04-20T18:08:04.619559Z",
     "shell.execute_reply": "2025-04-20T18:08:04.618717Z",
     "shell.execute_reply.started": "2025-04-20T18:08:04.615089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_average_embedding(tokens, model, vector_size):\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vectors.append(model.wv[token])\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    else:\n",
    "        return np.mean(vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:08:12.883939Z",
     "iopub.status.busy": "2025-04-20T18:08:12.883680Z",
     "iopub.status.idle": "2025-04-20T18:08:12.936805Z",
     "shell.execute_reply": "2025-04-20T18:08:12.935969Z",
     "shell.execute_reply.started": "2025-04-20T18:08:12.883920Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979, 300)\n"
     ]
    }
   ],
   "source": [
    "# For Word2Vec (300 dimensions)\n",
    "X_w2v = np.array([get_average_embedding(tokens, w2v_model, 300) for tokens in df['tokens']])\n",
    "print(X_w2v.shape)  # (number_of_tweets, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:08:22.955018Z",
     "iopub.status.busy": "2025-04-20T18:08:22.954732Z",
     "iopub.status.idle": "2025-04-20T18:08:23.008494Z",
     "shell.execute_reply": "2025-04-20T18:08:23.007648Z",
     "shell.execute_reply.started": "2025-04-20T18:08:22.954998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979, 300)\n"
     ]
    }
   ],
   "source": [
    "# For FastText (300 dimensions)\n",
    "X_fasttext = np.array([get_average_embedding(tokens, ft_model, 300) for tokens in df['tokens']])\n",
    "print(X_fasttext.shape)  # (number_of_tweets, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:08:31.752526Z",
     "iopub.status.busy": "2025-04-20T18:08:31.752271Z",
     "iopub.status.idle": "2025-04-20T18:08:31.756942Z",
     "shell.execute_reply": "2025-04-20T18:08:31.756130Z",
     "shell.execute_reply.started": "2025-04-20T18:08:31.752507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_average_embedding_glove(tokens, model, vector_size):\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model:\n",
    "            vectors.append(model[token])\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    else:\n",
    "        return np.mean(vectors, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:08:47.045263Z",
     "iopub.status.busy": "2025-04-20T18:08:47.044536Z",
     "iopub.status.idle": "2025-04-20T18:08:47.070917Z",
     "shell.execute_reply": "2025-04-20T18:08:47.070088Z",
     "shell.execute_reply.started": "2025-04-20T18:08:47.045242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979, 100)\n"
     ]
    }
   ],
   "source": [
    "# For GloVe (100 dimensions)\n",
    "X_glove = np.array([get_average_embedding_glove(tokens, glove_model, 100) for tokens in df['tokens']])\n",
    "print(X_glove.shape)  # (number_of_tweets, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:08:58.542339Z",
     "iopub.status.busy": "2025-04-20T18:08:58.542089Z",
     "iopub.status.idle": "2025-04-20T18:08:58.551505Z",
     "shell.execute_reply": "2025-04-20T18:08:58.550934Z",
     "shell.execute_reply.started": "2025-04-20T18:08:58.542321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Word2Vec\n",
    "X_w2v_train, X_w2v_test, y_w2v_train, y_w2v_test = train_test_split(X_w2v, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# FastText\n",
    "X_fasttext_train, X_fasttext_test, y_fasttext_train, y_fasttext_test = train_test_split(X_fasttext, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# GloVe\n",
    "X_glove_train, X_glove_test, y_glove_train, y_glove_test = train_test_split(X_glove, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:09:08.089762Z",
     "iopub.status.busy": "2025-04-20T18:09:08.089475Z",
     "iopub.status.idle": "2025-04-20T18:09:08.510873Z",
     "shell.execute_reply": "2025-04-20T18:09:08.509135Z",
     "shell.execute_reply.started": "2025-04-20T18:09:08.089741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Word2Vec model\n",
    "lr_w2v = LogisticRegression(max_iter=1000)\n",
    "lr_w2v.fit(X_w2v_train, y_w2v_train)\n",
    "\n",
    "# FastText model\n",
    "lr_fasttext = LogisticRegression(max_iter=1000)\n",
    "lr_fasttext.fit(X_fasttext_train, y_fasttext_train)\n",
    "\n",
    "# GloVe model\n",
    "lr_glove = LogisticRegression(max_iter=1000)\n",
    "lr_glove.fit(X_glove_train, y_glove_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:09:29.506889Z",
     "iopub.status.busy": "2025-04-20T18:09:29.506601Z",
     "iopub.status.idle": "2025-04-20T18:09:29.551659Z",
     "shell.execute_reply": "2025-04-20T18:09:29.550835Z",
     "shell.execute_reply.started": "2025-04-20T18:09:29.506871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Accuracy: 0.5663265306122449\n",
      "Word2Vec F1 Score: 0.5515374908680348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.37      0.44        91\n",
      "         1.0       0.57      0.73      0.64       105\n",
      "\n",
      "    accuracy                           0.57       196\n",
      "   macro avg       0.56      0.55      0.54       196\n",
      "weighted avg       0.56      0.57      0.55       196\n",
      "\n",
      "\n",
      "FastText Accuracy: 0.5612244897959183\n",
      "FastText F1 Score: 0.5369463645673322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.32      0.40        91\n",
      "         1.0       0.57      0.77      0.65       105\n",
      "\n",
      "    accuracy                           0.56       196\n",
      "   macro avg       0.56      0.55      0.53       196\n",
      "weighted avg       0.56      0.56      0.54       196\n",
      "\n",
      "\n",
      "GloVe Accuracy: 0.5510204081632653\n",
      "GloVe F1 Score: 0.4497200912295253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.10      0.17        91\n",
      "         1.0       0.55      0.94      0.69       105\n",
      "\n",
      "    accuracy                           0.55       196\n",
      "   macro avg       0.57      0.52      0.43       196\n",
      "weighted avg       0.57      0.55      0.45       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Word2Vec evaluation\n",
    "y_w2v_pred = lr_w2v.predict(X_w2v_test)\n",
    "print(\"Word2Vec Accuracy:\", accuracy_score(y_w2v_test, y_w2v_pred))\n",
    "print(\"Word2Vec F1 Score:\", f1_score(y_w2v_test, y_w2v_pred, average='weighted'))\n",
    "print(classification_report(y_w2v_test, y_w2v_pred))\n",
    "\n",
    "# FastText evaluation\n",
    "y_fasttext_pred = lr_fasttext.predict(X_fasttext_test)\n",
    "print(\"\\nFastText Accuracy:\", accuracy_score(y_fasttext_test, y_fasttext_pred))\n",
    "print(\"FastText F1 Score:\", f1_score(y_fasttext_test, y_fasttext_pred, average='weighted'))\n",
    "print(classification_report(y_fasttext_test, y_fasttext_pred))\n",
    "\n",
    "# GloVe evaluation\n",
    "y_glove_pred = lr_glove.predict(X_glove_test)\n",
    "print(\"\\nGloVe Accuracy:\", accuracy_score(y_glove_test, y_glove_pred))\n",
    "print(\"GloVe F1 Score:\", f1_score(y_glove_test, y_glove_pred, average='weighted'))\n",
    "print(classification_report(y_glove_test, y_glove_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:03:16.857929Z",
     "iopub.status.busy": "2025-04-20T18:03:16.857646Z",
     "iopub.status.idle": "2025-04-20T18:04:46.437243Z",
     "shell.execute_reply": "2025-04-20T18:04:46.436066Z",
     "shell.execute_reply.started": "2025-04-20T18:03:16.857911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:04:46.439524Z",
     "iopub.status.busy": "2025-04-20T18:04:46.439167Z",
     "iopub.status.idle": "2025-04-20T18:04:46.445192Z",
     "shell.execute_reply": "2025-04-20T18:04:46.444008Z",
     "shell.execute_reply.started": "2025-04-20T18:04:46.439487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:06:29.962894Z",
     "iopub.status.busy": "2025-04-20T18:06:29.962601Z",
     "iopub.status.idle": "2025-04-20T18:06:30.187426Z",
     "shell.execute_reply": "2025-04-20T18:06:30.186672Z",
     "shell.execute_reply.started": "2025-04-20T18:06:29.962878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:04:55.674490Z",
     "iopub.status.busy": "2025-04-20T18:04:55.674179Z",
     "iopub.status.idle": "2025-04-20T18:04:58.406229Z",
     "shell.execute_reply": "2025-04-20T18:04:58.405675Z",
     "shell.execute_reply.started": "2025-04-20T18:04:55.674471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load XLM-Roberta tokenizer and model\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "xlmr_model = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:05:13.948408Z",
     "iopub.status.busy": "2025-04-20T18:05:13.947698Z",
     "iopub.status.idle": "2025-04-20T18:05:22.522974Z",
     "shell.execute_reply": "2025-04-20T18:05:22.522068Z",
     "shell.execute_reply.started": "2025-04-20T18:05:13.948378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 979/979 [00:08<00:00, 119.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Device: GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "xlmr_model = xlmr_model.to(device)\n",
    "\n",
    "def get_xlmr_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = xlmr_model(**inputs)\n",
    "    # Take mean of the token embeddings (mean pooling)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.cpu().numpy().flatten()\n",
    "\n",
    "# Generate embeddings for all tweets\n",
    "xlmr_embeddings = []\n",
    "for text in tqdm(df['Tweet_clean']):\n",
    "    emb = get_xlmr_embedding(text)\n",
    "    xlmr_embeddings.append(emb)\n",
    "\n",
    "# Convert to numpy array\n",
    "import numpy as np\n",
    "X_xlmr = np.array(xlmr_embeddings)\n",
    "print(X_xlmr.shape)  # (num_samples, 768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:05:39.960259Z",
     "iopub.status.busy": "2025-04-20T18:05:39.959532Z",
     "iopub.status.idle": "2025-04-20T18:05:39.967314Z",
     "shell.execute_reply": "2025-04-20T18:05:39.966577Z",
     "shell.execute_reply.started": "2025-04-20T18:05:39.960234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_xlmr_train, X_xlmr_test, y_xlmr_train, y_xlmr_test = train_test_split(X_xlmr, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:06:33.091742Z",
     "iopub.status.busy": "2025-04-20T18:06:33.091451Z",
     "iopub.status.idle": "2025-04-20T18:06:33.581028Z",
     "shell.execute_reply": "2025-04-20T18:06:33.579445Z",
     "shell.execute_reply.started": "2025-04-20T18:06:33.091723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_xlmr = LogisticRegression(max_iter=1000)\n",
    "lr_xlmr.fit(X_xlmr_train, y_xlmr_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T18:07:05.100070Z",
     "iopub.status.busy": "2025-04-20T18:07:05.099503Z",
     "iopub.status.idle": "2025-04-20T18:07:05.116276Z",
     "shell.execute_reply": "2025-04-20T18:07:05.115518Z",
     "shell.execute_reply.started": "2025-04-20T18:07:05.100045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLM-R Accuracy: 0.6989795918367347\n",
      "XLM-R F1 Score: 0.6978143515470705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.64      0.66        91\n",
      "         1.0       0.71      0.75      0.73       105\n",
      "\n",
      "    accuracy                           0.70       196\n",
      "   macro avg       0.70      0.69      0.70       196\n",
      "weighted avg       0.70      0.70      0.70       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_xlmr_pred = lr_xlmr.predict(X_xlmr_test)\n",
    "print(\"XLM-R Accuracy:\", accuracy_score(y_xlmr_test, y_xlmr_pred))\n",
    "print(\"XLM-R F1 Score:\", f1_score(y_xlmr_test, y_xlmr_pred, average='weighted'))\n",
    "print(classification_report(y_xlmr_test, y_xlmr_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7197397,
     "sourceId": 11483587,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4167194,
     "sourceId": 7203508,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
