{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Basic libraries\nimport torch\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom torch.optim import AdamW\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nfrom tqdm import tqdm\nfrom datasets import load_dataset\n\n# For metrics\nfrom sklearn.metrics import accuracy_score\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:56:34.610239Z","iopub.execute_input":"2025-04-18T17:56:34.610920Z","iopub.status.idle":"2025-04-18T17:56:35.830300Z","shell.execute_reply.started":"2025-04-18T17:56:34.610894Z","shell.execute_reply":"2025-04-18T17:56:35.829558Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:02:34.865865Z","iopub.execute_input":"2025-04-18T18:02:34.866135Z","iopub.status.idle":"2025-04-18T18:02:34.870550Z","shell.execute_reply.started":"2025-04-18T18:02:34.866119Z","shell.execute_reply":"2025-04-18T18:02:34.869871Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"dataset = load_dataset('glue', 'sst2')\n\n# Check\nprint(dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:02:42.488159Z","iopub.execute_input":"2025-04-18T18:02:42.488686Z","iopub.status.idle":"2025-04-18T18:02:57.969025Z","shell.execute_reply.started":"2025-04-18T18:02:42.488654Z","shell.execute_reply":"2025-04-18T18:02:57.968296Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c24febac6154e3e88495928132931c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef5925cb3e004fa39ad2fd32d532aa67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bf427b9dd4d496099ae65741f52b8e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47b312fe545d487c925a363c905e2b9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1610c7f0abcf43bfb399b934c57fdba3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"433d3b185f424cb48ead5560e7e5756d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"760cfca1b8e24c4da3eb517337cefe59"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 1821\n    })\n})\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model_checkpoint = \"distilbert-base-uncased\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:03:48.402734Z","iopub.execute_input":"2025-04-18T18:03:48.403015Z","iopub.status.idle":"2025-04-18T18:04:04.139456Z","shell.execute_reply.started":"2025-04-18T18:03:48.402996Z","shell.execute_reply":"2025-04-18T18:04:04.138775Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3959535a182f43798edcdea40ef66dae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88a5e977aba541c29be461f04f5fa9a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99ca376da63c47cbb2b888ecee729f9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a169b799782b46288be574eb59086585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c441a1892fc4461baa2e2ddfc57b7830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ccb7289ca57430cb832b3789e8dd371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3e8b046043545d59ea996d20dc0d16c"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\ntokenized_datasets.set_format(\"torch\")\n\nfull_dataset = tokenized_datasets[\"train\"]\ntrain_size = int(0.8 * len(full_dataset))\nval_size = len(full_dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:04:06.489777Z","iopub.execute_input":"2025-04-18T18:04:06.490041Z","iopub.status.idle":"2025-04-18T18:04:06.506654Z","shell.execute_reply.started":"2025-04-18T18:04:06.490023Z","shell.execute_reply":"2025-04-18T18:04:06.505956Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"teacher_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\nstudent_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nteacher_model.to(device)\nstudent_model.to(device)\n\n# Freeze teacher model\nfor param in teacher_model.parameters():\n    param.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:04:09.847036Z","iopub.execute_input":"2025-04-18T18:04:09.847623Z","iopub.status.idle":"2025-04-18T18:04:15.296178Z","shell.execute_reply.started":"2025-04-18T18:04:09.847600Z","shell.execute_reply":"2025-04-18T18:04:15.295373Z"}},"outputs":[{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c39f21ba3224a2ca2df7b2064cf1344"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(student_model.parameters(), lr=5e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:04:20.233363Z","iopub.execute_input":"2025-04-18T18:04:20.233660Z","iopub.status.idle":"2025-04-18T18:04:20.239722Z","shell.execute_reply.started":"2025-04-18T18:04:20.233639Z","shell.execute_reply":"2025-04-18T18:04:20.239101Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"num_epochs = 2\nalpha = 0.5  # weight between hard loss and soft loss\ntemperature = 2.0  # soften the logits\n\nloss_fn = nn.CrossEntropyLoss()  # for hard labels\n\nfor epoch in range(num_epochs):\n    student_model.train()\n    running_loss = 0.0\n\n    for batch in tqdm(train_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        input_ids = batch['input_ids']\n        attention_mask = batch['attention_mask']\n        labels = batch['label']\n\n        # Forward pass through teacher\n        with torch.no_grad():\n            teacher_outputs = teacher_model(input_ids=input_ids, attention_mask=attention_mask)\n            teacher_logits = teacher_outputs.logits / temperature  # soften\n\n        # Forward pass through student\n        student_outputs = student_model(input_ids=input_ids, attention_mask=attention_mask)\n        student_logits = student_outputs.logits / temperature\n\n        # Losses\n        hard_loss = loss_fn(student_logits, labels)\n        soft_loss = F.kl_div(F.log_softmax(student_logits, dim=-1), F.softmax(teacher_logits, dim=-1), reduction=\"batchmean\")\n\n        total_loss = alpha * hard_loss + (1 - alpha) * soft_loss\n\n        # Backpropagation\n        optimizer.zero_grad()\n        total_loss.backward()\n        optimizer.step()\n\n        running_loss += total_loss.item()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:05:06.456275Z","iopub.execute_input":"2025-04-18T18:05:06.456552Z"}},"outputs":[{"name":"stderr","text":" 82%|████████▏ | 2763/3368 [28:57<06:19,  1.59it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            input_ids = batch['input_ids']\n            attention_mask = batch['attention_mask']\n            labels = batch['label']\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            preds = outputs.logits.argmax(dim=-1)\n\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    return correct / total\n\naccuracy = evaluate(student_model, val_loader)\nprint(f\"Validation Accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}